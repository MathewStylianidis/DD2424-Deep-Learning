{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this assignment, a simple ConvNet is implemented and trained to predict the language of a surname from its spelling in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.linalg import block_diag\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ConvNet class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet:\n",
    "    \"\"\"\n",
    "    A simple ConvNet implementation with 2 convolutional layers \n",
    "    followed by a fully connected layer and a softmax output \n",
    "    layer.\n",
    "    \n",
    "    Attributes:\n",
    "        n: A list of the number of filters applied at each convo-\n",
    "            lutional layer.\n",
    "        k: A list of the width of the filter window applied in each\n",
    "            convolutional layer.\n",
    "        input_dim: dimensionality of input (number of unique characters)\n",
    "        output_dim: dimensionality of output\n",
    "        max_length: maximum number of characters in an input\n",
    "        nlen_list: List with the number of columns of the input when in its original form\n",
    "            before being vectorized, for each layer.\n",
    "        eta: initial learning rate value\n",
    "        rho: momentum constant term\n",
    "        F: list of filters/weights for each one of the convolutional\n",
    "            layers.\n",
    "        W: Weights of the fully connected layer\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n, k, output_dim, input_dim, nlen, eta = 0.001, rho = 0.9, he_init = False):\n",
    "        \"\"\"\n",
    "        Initializes the convolutional neural network\n",
    "    \n",
    "        Args:\n",
    "            he_init: When True He-initialization is performed for the weights\n",
    "            nlen: Number of columns of the input when in its original form\n",
    "            before being vectorized.\n",
    "        Raises:\n",
    "            Exception if the size of n and k is not the same.\n",
    "        \"\"\"\n",
    "        if(len(n) != len(k)):\n",
    "            raise Exception(\"The number of layers specified by <n> \" \\\n",
    "                            \"and <k> should be equal.\")\n",
    "        self.n = list(n)\n",
    "        self.k = list(k)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.max_length = nlen\n",
    "        \n",
    "        # TODO: Change He initialization for first layer due to the sparse nature of the input\n",
    "        self.F = []\n",
    "        if he_init is True:\n",
    "            self.F.append(np.random.normal(0, np.sqrt(2/nlen), (input_dim, self.k[0], self.n[0])))\n",
    "        else:\n",
    "            self.F.append(np.random.normal(0, 1, (input_dim, self.k[0], self.n[0])))\n",
    "        self.nlen_list = [nlen - self.k[0] + 1]\n",
    "        \n",
    "        for i in range(1, len(n)):\n",
    "            if he_init is True:\n",
    "                self.F.append(np.random.normal(0, np.sqrt(2/self.nlen_list[-1]), (self.n[i - 1], self.k[i], self.n[i])))\n",
    "            else:\n",
    "                self.F.append(np.random.normal(0, 1, (self.n[i - 1], self.k[i], self.n[i])))\n",
    "            self.nlen_list.append(self.nlen_list[-1] - self.k[1] + 1)\n",
    "        fsize = self.n[-1] * self.nlen_list[-1]\n",
    "        if he_init is True:\n",
    "            self.W = np.random.normal(0, np.sqrt(2/self.nlen_list[-1]), (output_dim, fsize))\n",
    "        else:\n",
    "            self.W = np.random.normal(0, 1, (output_dim, fsize))\n",
    "    \n",
    "    def softmax(self, s):\n",
    "        \"\"\"\n",
    "        Implementation of the softmax activation function\n",
    "\n",
    "        Args:\n",
    "            s: an 1xd vector of a classifier's outputs\n",
    "\n",
    "        Returns:\n",
    "            An 1xd vector with the results of softmax given the input\n",
    "            vector s.\n",
    "        \"\"\"\n",
    "        exponents = np.exp(s - np.max(s, axis = 0)) # Max subtraction for numerical stability\n",
    "        output_exp_sum = np.sum(exponents, axis = 0)\n",
    "        p = exponents / output_exp_sum\n",
    "        return p\n",
    "\n",
    "    def constructFilterMatrix(self, F, nlen):\n",
    "        \"\"\"\n",
    "        Constructs the matrix of the filters of a layer used to\n",
    "        perform the convolution by matrix multiplication.\n",
    "        \n",
    "        Args:\n",
    "            F: A N x k x nf containing the convolutional filters\n",
    "                of a certain layer where N is the height of the convo-\n",
    "                lutional filter, k is its width and nf is the number of\n",
    "                filters in the layer.\n",
    "            nlen: Number of columns in the input of that layer. \n",
    "        \n",
    "        Returns:\n",
    "            An (nlen - k + 1) * nf x nlen * N matrix that can be used to\n",
    "            perform the convolution when multiplied by the\n",
    "            vectorized input.\n",
    "        \"\"\"\n",
    "        nf = F.shape[2]\n",
    "        vec_filters = F.transpose(2,1,0).reshape(nf, F.shape[0] * F.shape[1])\n",
    "        MF_matrix = np.zeros(((nlen - F.shape[1] + 1) * nf, nlen * F.shape[0]))\n",
    "        cur_column = 0\n",
    "        # For each time the filters are applied\n",
    "        for i in range(nlen - F.shape[1] + 1):\n",
    "            # Fill in the zero slots of the MF_Matrix with the vectorized filters\n",
    "            MF_matrix[i * nf: i * nf + nf, cur_column *  F.shape[0]: cur_column *  F.shape[0] + vec_filters.shape[1]] = vec_filters\n",
    "            cur_column += 1\n",
    "        return MF_matrix\n",
    "        \n",
    "    def makeMXMatrix(self, vec_input, height, width, nf, nlen):\n",
    "        \"\"\"\n",
    "        Computes the input matrix used for the convolutions during the \n",
    "        back-propagation.\n",
    "        \n",
    "        Args:\n",
    "            vec_input: Vectorized version of the input to the convolutional\n",
    "                layer.\n",
    "            height: corresponding height of the filter\n",
    "            width: corresponding width of the filter\n",
    "            filter_no: number of filters to be applied\n",
    "            nlen: Number of columns in the input of that layer. \n",
    "        Returns:\n",
    "            A (nlen - k + 1) * filter_no x k * filter_no * height with the\n",
    "            results of the convolutions.\n",
    "        \"\"\"\n",
    "        MX_Matrix = np.zeros(((nlen - width + 1) * nf, width * nf * height))\n",
    "        cur_column = 0\n",
    "        for i in range(nlen - width + 1):\n",
    "            # Define block diagonal matrix with the inputs to be used in this convolution on the diagonal\n",
    "            MX_Matrix[i * nf : i * nf + nf, :] = \\\n",
    "                block_diag(*[vec_input[cur_column * height: cur_column * height + width * height] for j in range(nf)]) \n",
    "            cur_column += 1\n",
    "        return MX_Matrix\n",
    "    \n",
    "    def cross_entropy_loss(self, X, Y, MFs):\n",
    "        \"\"\"\n",
    "        Calculates the cross entropy loss\n",
    "        \"\"\"\n",
    "        log_X = np.multiply(Y , self.forwardPass(X, MFs)[0]).sum(axis=0)\n",
    "        log_X[log_X == 0] = np.finfo(float).eps\n",
    "        return -np.log(log_X)\n",
    "\n",
    "    \n",
    "    def computeLoss(self, X_batch, Y_batch, MFs):\n",
    "        \"\"\"\n",
    "        Computes the loss of the network given a batch of data.\n",
    "        \n",
    "        Args:\n",
    "            X_batch: NxD matrix with N data sample inputs\n",
    "            Y_batch: NxM matrix with N data sample outputs\n",
    "        \n",
    "        Returns:\n",
    "            A scalar float value corresponding to the loss.\n",
    "        \"\"\"        \n",
    "        return np.mean(self.cross_entropy_loss(X_batch, Y_batch, MFs))# + lamda * np.sum(self.W ** 2)\n",
    "\n",
    "    def computeAccuracy(self, X, y, MFs):\n",
    "        \"\"\"\n",
    "        Computes the accuracy of the network.\n",
    "\n",
    "        Args:\n",
    "            X: Input matrix\n",
    "            y: Output labels\n",
    "\n",
    "        Returns:\n",
    "            The accuracy of the network (i.e. the percentage of\n",
    "            correctly classified inputs in X).\n",
    "\n",
    "        \"\"\"\n",
    "        softmax_outputs = self.forwardPass(X, MFs)[0] # Get probability distribution of outputs\n",
    "        # Reduce to a vector of the labels with the highest probability\n",
    "        predictions = np.argmax(softmax_outputs, axis = 0)\n",
    "        accuracy = (predictions == y).mean()\n",
    "        return accuracy\n",
    "\n",
    "    def forwardPass(self, X_batch, MFs):\n",
    "        \"\"\"\n",
    "        Performs a forward pass and returns the result:\n",
    "        \n",
    "        Args:\n",
    "            X_batch: NxD matrix with N data sample inputs\n",
    "            MFs: Matrices needed to perform convolution as \n",
    "                matrix multiplication.\n",
    "            \n",
    "        Returns:\n",
    "            A matrix with the predicted one-hot representations along with the outputs\n",
    "            of the first and second layer as well as the MF matrices calculated.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply first convolutional layer to input data followed by a ReLU activation\n",
    "        X_batch1 = MFs[0].dot(X_batch)\n",
    "        X_batch1[X_batch1 < 0.0] = 0.0\n",
    "        \n",
    "        # Apply second convolutional layer to input data followed by a ReLU activation\n",
    "        X_batch2 = MFs[1].dot(X_batch1)\n",
    "        X_batch2[X_batch2 < 0.0] = 0.0\n",
    "        \n",
    "        # Apply the fully connected layer\n",
    "        output = self.W.dot(X_batch2)\n",
    "        # Apply softmax\n",
    "        P_batch = self.softmax(output)\n",
    "        return P_batch, X_batch1, X_batch2\n",
    "    \n",
    "    def backwardPass(self, Y_batch, P_batch, X_batch, X_batch1, X_batch2):\n",
    "        \"\"\"\n",
    "        Performs a backward pass and returns the gradients:\n",
    "        \n",
    "        Args:\n",
    "            Y_batch: NxM matrix with N data sample outputs\n",
    "            P_batch: Output after the softmax activation layer\n",
    "            X_batch2: Output of the second convolutional layer after the ReLU.\n",
    "            X_batch1: Output of the first convolutional layer after the ReLU.\n",
    "            X_batch: Original batch with the inputs.\n",
    "            \n",
    "        Returns:\n",
    "            The gradients of the weights of each layer (i.e. grad_F1, grad_F2, grad_W).\n",
    "        \"\"\"\n",
    "        # Initialize all gradients to zero\n",
    "        grad_W = np.zeros(self.W.shape) \n",
    "        grad_F1 = np.zeros(self.F[0].shape)\n",
    "        grad_F2 = np.zeros(self.F[1].shape)\n",
    "        \n",
    "        # Compute gradient of W\n",
    "        n = Y_batch.shape[1]\n",
    "        G_batch = -(Y_batch - P_batch)\n",
    "        grad_W = G_batch.dot(X_batch2.T) / n\n",
    "        \n",
    "        \n",
    "        # Propagate gradient through fully connected layer and ReLU of 2nd layer\n",
    "        G_batch = self.W.T.dot(G_batch)\n",
    "        G_batch *= np.where(X_batch2 > 0, 1, 0)\n",
    "        \n",
    "        # Compute gradient of the second layer's filters\n",
    "        n = X_batch1.shape[1]\n",
    "        for j in range(n):\n",
    "            g_j = G_batch[:,j]\n",
    "            x_j = X_batch1[:,j]\n",
    "            MX_matrix = self.makeMXMatrix(x_j, *self.F[1].shape, self.nlen_list[0])\n",
    "            v = g_j.T.dot(MX_matrix)\n",
    "            grad_F2 += v.reshape(grad_F2.shape, order='F')\n",
    "        grad_F2 /= n\n",
    "        \n",
    "        # Propagate gradient through second convolutional layer and ReLU of 1st layer\n",
    "        G_batch = MF_Matrix2.T.dot(G_batch)\n",
    "        G_batch *= np.where(X_batch1 > 0, 1, 0)\n",
    "        \n",
    "        # Compute gradient of the first layer's filters\n",
    "        n = X_batch.shape[1]\n",
    "        for j in range(n):\n",
    "            g_j = G_batch[:,j]\n",
    "            x_j = X_batch[:,j]\n",
    "            MX_matrix = self.makeMXMatrix(x_j, *self.F[0].shape, self.max_length)\n",
    "            v = g_j.T.dot(MX_matrix)\n",
    "            grad_F1 += v.reshape(grad_F1.shape, order='F')\n",
    "        grad_F1 /= n       \n",
    "        \n",
    "        return grad_F1, grad_F2, grad_W\n",
    "    \n",
    " \n",
    "    \n",
    "    def compute_grad_num_slow(self, X_batch, Y_batch, h = 1e-6):\n",
    "        '''Centered difference gradient'''\n",
    "        # Initialize all gradients to zero\n",
    "        grad_W = np.zeros(self.W.shape) \n",
    "        grad_F1 = np.zeros(self.F[0].shape)\n",
    "        grad_F2 = np.zeros(self.F[1].shape)\n",
    "\n",
    "        MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "        MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0]))\n",
    "        \n",
    "        for j in tqdm(range(self.W.shape[0])):\n",
    "            for k in range(self.W.shape[1]):\n",
    "                self.W[j, k] -= h\n",
    "                c1 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "                self.W[j, k] += 2 * h\n",
    "                c2 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "                self.W[j, k] -= h\n",
    "                grad_W[j, k] = (c2-c1) / (2 * h)\n",
    "        \n",
    "        \n",
    "        for j in tqdm(range(self.F[1].shape[0])):\n",
    "            for k in range(self.F[1].shape[1]):\n",
    "                for i in range(self.F[1].shape[2]):\n",
    "                    self.F[1][j, k, i] = h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c1 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[1][j, k, i]  += 2 * h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c2= self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[1][j, k, i]  -= h\n",
    "                    grad_F2[j, k, i]  = (c2-c1) / (2 * h)\n",
    "\n",
    "        \n",
    "        for j in tqdm(range(self.F[0].shape[0])):\n",
    "            for k in range(self.F[0].shape[1]):\n",
    "                for i in range(self.F[0].shape[2]):\n",
    "                    self.F[0][j, k, i]  -= h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c1 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[0][j, k, i]  += 2 * h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c2= self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[0][j, k, i]  -= h\n",
    "                    grad_F1[j, k] = (c2-c1) / (2 * h)\n",
    "\n",
    "                \n",
    "        return grad_F1, grad_F2, grad_W\n",
    "    \n",
    "    def miniBatchGD(self, X, Y, GDparams, verbose = False, X_val = None, Y_val = None, tol = 1e-10):\n",
    "        \"\"\"\n",
    "        Implementation of mini-batch gradient descent.\n",
    "\n",
    "         Args:\n",
    "            X: Training input matrix\n",
    "            Y: Training set desired output matrix\n",
    "            GDparams: Object of the class Params with the hyperparameters\n",
    "                used for learning.\n",
    "            verbose: Prints info in each iteration about the progress of\n",
    "                training when equal to True.\n",
    "            X_val: Validation set input matrix\n",
    "            Y_val: Validation set desired output matrix\n",
    "\n",
    "        Returns:\n",
    "            The following tuple is returned where the validation lists\n",
    "            are empty if no validation set is given: (training_loss_list,\n",
    "            validation_loss_list, training_acc_list, validation_acc_list).\n",
    "        \"\"\"\n",
    "        results = ([],[],[],[])\n",
    "        mini_batch_count = X.shape[0] // GDparams.n_batch\n",
    "        y = np.argmax(Y, axis = 0)\n",
    "        \n",
    "        MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "        MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0]))\n",
    "        \n",
    "        if(X_val is not None and Y_val is not None):\n",
    "            y_val = np.argmax(Y_val, axis = 0)\n",
    "        results[0].append(self.computeLoss(X, Y, MFs))\n",
    "        results[2].append(self.computeAccuracy(X, y, MFs))\n",
    "        \n",
    "        if(X_val is not None and Y_val is not None):\n",
    "            results[1].append(self.computeLoss(X_val, Y_val, MFs))\n",
    "            results[3].append(self.computeAccuracy(X_val, y_val, MFs))\n",
    "            \n",
    "        if(verbose):\n",
    "                print(\"Starting state \")\n",
    "                print(\"    Training cost: \" + str(results[0][-1]))\n",
    "                print(\"    Training accuracy: \" + str(results[2][-1]))\n",
    "                if(X_val is not None and Y_val is not None):\n",
    "                    print(\"    Validation cost: \" + str(results[1][-1]))\n",
    "                    print(\"    Validation accuracy: \" + str(results[3][-1]))\n",
    "                    \n",
    "        # If momentum is used\n",
    "        if GDparams.rho != 0.0:\n",
    "            # Create zero matrix for each parameter\n",
    "            V_W = np.zeros(self.W.shape)\n",
    "            V_F2 = np.zeros(self.F[1].shape)\n",
    "            V_F1 = np.zeros(self.F[0].shape)\n",
    "                    \n",
    "        learning_rate = GDparams.eta\n",
    "        for i in tqdm(range(GDparams.n_epochs)):\n",
    "            for j in range(mini_batch_count):\n",
    "                if(j < mini_batch_count - 1):\n",
    "                    start = j * GDparams.n_batch\n",
    "                    end = start + GDparams.n_batch\n",
    "                    mini_batch_input = X[:,start:end]\n",
    "                    mini_batch_output = Y[:,start:end]\n",
    "                else:\n",
    "                    # Take the remaining samples in the last mini batch\n",
    "                    mini_batch_input = X[:,j * GDparams.n_batch:]\n",
    "                    mini_batch_output = Y[:,j * GDparams.n_batch:]\n",
    "                \n",
    "                # Construct MF Matrices\n",
    "                MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0]))\n",
    "                P_batch, X_batch1, X_batch2 = self.forwardPass(mini_batch_input, MFs)\n",
    "                grad_F1, grad_F2, grad_W = self.backwardPass(mini_batch_output, P_batch, mini_batch_input,\\\n",
    "                                                             X_batch1, X_batch2)\n",
    "\n",
    "                # Converge if all gradients are zero\n",
    "                if np.all(grad_W < tol) == 0 and np.all(grad_F1 < tol) and np.all(grad_F2 < tol):\n",
    "                    print(\"Learning converged at epoch \" + str(i))\n",
    "                    break              \n",
    "                \n",
    "                if GDparams.rho == 0.0:\n",
    "                    self.W[0] -= learning_rate * grad_W\n",
    "                    self.F[1] -= learning_rate * grad_F2\n",
    "                    self.F[0] -= learning_rate * grad_F1\n",
    "                else:\n",
    "                    V_W = GDparams.rho * V_W + learning_rate * grad_W\n",
    "                    V_F2 = GDparams.rho * V_F2 + learning_rate * grad_F2\n",
    "                    V_F1 = GDparams.rho * V_F1 + learning_rate * grad_F1\n",
    "                    self.W -= V_W\n",
    "                    self.F[1] -= V_F2\n",
    "                    self.F[0] -= V_F1\n",
    "                    \n",
    "            # Decay the learning rate\n",
    "            learning_rate *= GDparams.decay_rate\n",
    "\n",
    "            results[0].append(self.computeLoss(X, Y, MFs))\n",
    "            results[2].append(self.computeAccuracy(X, y, MFs))\n",
    "            if(X_val is not None and Y_val is not None):\n",
    "                results[1].append(self.computeLoss(X_val, Y_val, MFs))\n",
    "                results[3].append(network_model.computeAccuracy(X_val, y_val, MFs))\n",
    "            if(verbose):\n",
    "                print(\"Iteration \" + str(i))\n",
    "                print(\"    Training cost: \" + str(results[0][-1]))\n",
    "                print(\"    Training accuracy: \" + str(results[2][-1]))\n",
    "                if(X_val is not None and Y_val is not None):\n",
    "                    print(\"    Validation cost: \" + str(results[1][-1]))\n",
    "                    print(\"    Validation accuracy: \" + str(results[3][-1]))\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    \"\"\"\n",
    "    Class containing hyperparameters used for\n",
    "    gradient descent learning.\n",
    "    \n",
    "    Attributes:\n",
    "        n_batch: Number of samples in each mini-batch.\n",
    "        eta: Learning rate\n",
    "        n_epochs: Maximum number of learning epochs.\n",
    "        decay_rate: The percentage of decay of the learning rate after each epoch, i.e.\n",
    "            a factor less than 1 by which the learning rate gets multiplied after each \n",
    "            epoch.\n",
    "        rho: percentage of use of the gradients of previous turns in learning to add momentum\n",
    "    \"\"\"\n",
    "    def __init__(self, n_batch, eta, n_epochs, decay_rate = 1.0, rho = 0.0):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.n_batch = n_batch\n",
    "        self.eta = eta\n",
    "        self.n_epochs = n_epochs\n",
    "        self.decay_rate = decay_rate\n",
    "        self.rho = rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelativeErrors(grad1, grad2):\n",
    "    \"\"\"\n",
    "    Computes the relative errors of grad_1 and grad_2 gradients\n",
    "    \"\"\"\n",
    "    abs_diff = np.absolute(grad1 - grad2) \n",
    "    abs_sum = np.absolute(grad1) + np.absolute(grad2)\n",
    "    max_elems = np.where(abs_sum > np.finfo(float).eps, abs_sum, np.finfo(float).eps)\n",
    "    relativeErrors = abs_diff / max_elems\n",
    "    return relativeErrors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeString(string, character_dictionary, max_length):\n",
    "    \"\"\"\n",
    "    One-hot encodes the character string, converting each \n",
    "    of its letters to one-hot encoded vectors and stacking\n",
    "    them from left to right. \n",
    "    \n",
    "    Args:\n",
    "        name: The string to be encoded.\n",
    "        character_dictionary: A dictionary which has a unique\n",
    "            index for each character in the alphabet used by\n",
    "            the string.\n",
    "        max_length: maximum length of the string. If the string\n",
    "            has a length less than max_length, zero columnds are\n",
    "            added as padding after the encoded character columns.\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "        A C x max_length vector with the one-hot encoded characters\n",
    "        of the string and possibly zero padding in the last columns\n",
    "        where C is the number of different characters in the alpha-\n",
    "        bet used.\n",
    "    \"\"\"\n",
    "    d = len(character_dictionary)\n",
    "    encoded_string = np.zeros((d, max_length))\n",
    "    for i in range(len(string)):\n",
    "        encoded_string[character_dictionary[string[i]],i] = 1\n",
    "    return encoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(label_id, label_no):\n",
    "    \"\"\"\n",
    "    Returns a one-hot encoded numpy vector with 1 at the index\n",
    "    of the label and 0 for each other element.\n",
    "    \n",
    "    Args:\n",
    "        label_id: Index of label.\n",
    "        label_no: Number of total labels.\n",
    "    \n",
    "    Returns:\n",
    "        A one-hot encoded vector with label_no elements.\n",
    "    \"\"\"\n",
    "    vector = np.zeros(label_no) \n",
    "    vector[label_id] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the files containing the data\n",
    "name_path = \"ascii_names.txt\"\n",
    "category_labels_path = \"category_labels.txt\"\n",
    "# Path to file used to save the inputs after their encoding\n",
    "save_input_path = \"onehot_encoded_inputs.npy\"\n",
    "# Path to file with the indices of the inputs that are going to used in the validation set\n",
    "val_ind_path = \"Validation_Inds.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20050it [00:00, 1002608.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "names = []\n",
    "labels = []\n",
    "if(os.path.exists(name_path)):\n",
    "    with open(name_path,\"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            entry = line.split()\n",
    "            names.append(' '.join(entry[:-1]))\n",
    "            labels.append(entry[-1])\n",
    "    f.close()\n",
    "    names = np.array(names)\n",
    "    labels = np.array(labels, dtype = int) \n",
    "else:\n",
    "    print(\"Requested file \" + name_path + \" does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Arabic\n"
     ]
    }
   ],
   "source": [
    "# Read the different class names and indices and build a dictionary\n",
    "if(os.path.exists(category_labels_path)):\n",
    "    class_names = np.loadtxt(category_labels_path, usecols = 1, dtype = str)\n",
    "    class_indices = np.loadtxt(category_labels_path, usecols = 0, dtype = int)\n",
    "    K = len(class_names)\n",
    "    class_dictionary = {}\n",
    "    for i in range(K):\n",
    "        class_dictionary[class_names[i]] = class_indices[i]\n",
    "    inv_class_dictionary = {v: k for k, v in class_dictionary.items()}\n",
    "    # Check for correctness\n",
    "    print(class_dictionary['Arabic'])\n",
    "    print(inv_class_dictionary[1])\n",
    "else: \n",
    "    print(\"Requested file \" + category_labels_path + \" does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine number of unique characters and set up dictionary / Determine maximum length of name in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 20050/20050 [00:00<00:00, 455579.07it/s]\n"
     ]
    }
   ],
   "source": [
    "character_dictionary = {}\n",
    "unique_idx = 0\n",
    "max_length = -1\n",
    "for name in tqdm(names):\n",
    "    length = len(name)\n",
    "    if(length > max_length):\n",
    "        max_length = length\n",
    "    for i in range(len(name)):\n",
    "        if(name[i] not in character_dictionary.keys()):\n",
    "            character_dictionary[name[i]] = unique_idx\n",
    "            unique_idx += 1\n",
    "d = len(character_dictionary) # Get number of unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFFERENT UNIQUE CHARACTERS: 55\n",
      "MAXIMUM NAME LENGTH: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"DIFFERENT UNIQUE CHARACTERS: \" + str(d))\n",
    "print(\"MAXIMUM NAME LENGTH: \" + str(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# Build inverse dictionary mapping\n",
    "inv_character_dictionary = {v: k for k, v in character_dictionary.items()}\n",
    "# Check for correctness\n",
    "print(character_dictionary['o'])\n",
    "print(inv_character_dictionary[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding and vectorization of the input names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 20050/20050 [00:00<00:00, 31501.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode and save the inputs in a matrix when each column corresponds to a different name\n",
    "vectorized_input_size = d * max_length\n",
    "X = np.zeros((vectorized_input_size, names.shape[0]))\n",
    "for idx, name in enumerate(tqdm(names)):\n",
    "    X[:,idx] = encodeString(name, character_dictionary, max_length).flatten(order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save inputs in a file if they are not already saved\n",
    "if(not os.path.exists(save_input_path)):\n",
    "    np.save(save_input_path, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the inputs that are going to used in the validation set\n",
    "if(os.path.exists(val_ind_path)):\n",
    "    validation_indices = np.loadtxt(val_ind_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for outputputs\n",
    "Y = np.array([one_hot_encoding(label - 1, K) for label in labels], order = 'F').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters & initialize the ConvNet's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_width_constants = [3, 3]\n",
    "K = len(class_dictionary)\n",
    "conv_net = ConvNet(n = filter_numbers , k = filter_width_constants, output_dim = K, \\\n",
    "                   input_dim = d, nlen = max_length, he_init = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Debug based on saved filters and convolution outputs\n",
    "dictionary = loadmat(\"Debugging_files/DebugInfo\")\n",
    "x_input = dictionary['x_input'].reshape(1, -1)\n",
    "X_input = dictionary['X_input']\n",
    "F = dictionary['F']\n",
    "vecS = dictionary['vecS']\n",
    "MF_Matrix = conv_net.constructFilterMatrix(F, max_length)\n",
    "s = MF_Matrix.dot(x_input.reshape(-1, 1)).flatten()\n",
    "print(np.allclose(s, vecS.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_Matrix = conv_net.constructFilterMatrix(conv_net.F[0], max_length)\n",
    "MF_Matrix2 = conv_net.constructFilterMatrix(conv_net.F[1], conv_net.nlen_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7e5e66198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7e79dcb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the mf_matrix to confirm that it is block diagonal\n",
    "plt.pcolormesh(MF_Matrix)\n",
    "plt.show()\n",
    "plt.pcolormesh(MF_Matrix2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "MX_Matrix = conv_net.makeMXMatrix((X[:,17513]), *conv_net.F[0].shape, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Debugging for make MX and make MF functions (s1 and s2 should be equal)\n",
    "s1 = MX_Matrix.dot(conv_net.F[0].flatten('F').reshape(-1, 1))\n",
    "s2 = MF_Matrix.dot(X[:,17513].reshape(-1, 1))\n",
    "print(np.allclose(s1,s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct MF Matrices\n",
    "MFs = [conv_net.constructFilterMatrix(conv_net.F[0], conv_net.max_length)]\n",
    "MFs.append(conv_net.constructFilterMatrix(conv_net.F[1], conv_net.nlen_list[0]))\n",
    "P_batch, X_batch1, X_batch2 = conv_net.forwardPass(X[:,:100], MFs)\n",
    "grad_F1, grad_F2, grad_W = conv_net.backwardPass(Y[:,:100], P_batch, X[:,:100], X_batch1, X_batch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:01<00:00,  9.84it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 42.37it/s]\n",
      "100%|██████████████████████████████████████████| 55/55 [00:01<00:00, 46.39it/s]\n"
     ]
    }
   ],
   "source": [
    "grad_F1_approx, grad_F2_approx, grad_W_approx = conv_net.compute_grad_num_slow(X[:,:100], Y[:,:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.00021089944158778214\n",
      "0.40937187004764514\n",
      "0.779356352780695\n",
      "5.472949890316788e-07\n"
     ]
    }
   ],
   "source": [
    "errors1 = getRelativeErrors(grad_F1, grad_F1_approx)\n",
    "errors2 = getRelativeErrors(grad_F2, grad_F2_approx)\n",
    "errors3 = getRelativeErrors(grad_W, grad_W_approx)\n",
    "print(np.max(errors1))\n",
    "print(np.max(errors2))\n",
    "print(np.max(errors3))\n",
    "\n",
    "print(np.mean(errors1))\n",
    "print(np.mean(errors2))\n",
    "print(np.mean(errors3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state \n",
      "    Training cost: 2.8903728726393356\n",
      "    Training accuracy: 0.018952618453865335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/5 [00:00<?, ?it/s]D:\\Anaconda3\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "    Training cost: 9.264484084676685\n",
      "    Training accuracy: 0.09980049875311721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 1/5 [00:35<02:20, 35.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "    Training cost: 6.035728679465362\n",
      "    Training accuracy: 0.1002992518703242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 2/5 [01:10<01:45, 35.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2\n",
      "    Training cost: 3.556069220493581\n",
      "    Training accuracy: 0.2283790523690773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 3/5 [01:47<01:11, 35.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3\n",
      "    Training cost: 3.8796835259254188\n",
      "    Training accuracy: 0.2374064837905237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 4/5 [02:23<00:35, 35.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4\n",
      "    Training cost: 3.2873372662848515\n",
      "    Training accuracy: 0.28982543640897757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [02:59<00:00, 35.85s/it]\n"
     ]
    }
   ],
   "source": [
    "rho = 0.9\n",
    "epochs = 5\n",
    "mini_batch_size = 100\n",
    "decay_rate = 0.95\n",
    "eta = 0.05\n",
    "GDparams = Params(mini_batch_size, eta, epochs, decay_rate, rho)\n",
    "results = conv_net.miniBatchGD(X, Y, GDparams, verbose = True, X_val = None, Y_val = None, tol = 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
