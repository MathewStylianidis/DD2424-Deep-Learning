{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this assignment, a simple ConvNet is implemented and trained to predict the language of a surname from its spelling in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ConvNet class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the convolutional neural network\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeString(string, character_dictionary, max_length):\n",
    "    \"\"\"\n",
    "    One-hot encodes the character string, converting each \n",
    "    of its letters to one-hot encoded vectors and stacking\n",
    "    them from left to right. \n",
    "    \n",
    "    Args:\n",
    "        name: The string to be encoded.\n",
    "        character_dictionary: A dictionary which has a unique\n",
    "            index for each character in the alphabet used by\n",
    "            the string.\n",
    "        max_length: maximum length of the string. If the string\n",
    "            has a length less than max_length, zero columnds are\n",
    "            added as padding after the encoded character columns.\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "        A C x max_length vector with the one-hot encoded characters\n",
    "        of the string and possibly zero padding in the last columns\n",
    "        where C is the number of different characters in the alpha-\n",
    "        bet used.\n",
    "    \"\"\"\n",
    "    d = len(character_dictionary)\n",
    "    encoded_string = np.zeros((d, max_length))\n",
    "    for i in range(len(string)):\n",
    "        encoded_string[character_dictionary[string[i]],i] = 1\n",
    "    return encoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the files containing the data\n",
    "name_path = \"ascii_names.txt\"\n",
    "category_labels_path = \"category_labels.txt\"\n",
    "# Path to file used to save the inputs after their encoding\n",
    "save_input_path = \"onehot_encoded_inputs.npy\"\n",
    "# Path to file with the indices of the inputs that are going to used in the validation set\n",
    "val_ind_path = \"Validation_Inds.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20050it [00:00, 1002644.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "names = []\n",
    "labels = []\n",
    "if(os.path.exists(name_path)):\n",
    "    with open(name_path,\"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            entry = line.split()\n",
    "            names.append(' '.join(entry[:-1]))\n",
    "            labels.append(entry[-1])\n",
    "    f.close()\n",
    "    names = np.array(names)\n",
    "    labels = np.array(labels, dtype = int) \n",
    "else:\n",
    "    print(\"Requested file \" + name_path + \" does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Arabic\n"
     ]
    }
   ],
   "source": [
    "# Read the different class names and indices and build a dictionary\n",
    "if(os.path.exists(category_labels_path)):\n",
    "    class_names = np.loadtxt(category_labels_path, usecols = 1, dtype = str)\n",
    "    class_indices = np.loadtxt(category_labels_path, usecols = 0, dtype = int)\n",
    "    K = len(class_names)\n",
    "    class_dictionary = {}\n",
    "    for i in range(K):\n",
    "        class_dictionary[class_names[i]] = class_indices[i]\n",
    "    inv_class_dictionary = {v: k for k, v in class_dictionary.items()}\n",
    "    # Check for correctness\n",
    "    print(class_dictionary['Arabic'])\n",
    "    print(inv_class_dictionary[1])\n",
    "else: \n",
    "    print(\"Requested file \" + category_labels_path + \" does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine number of unique characters and set up dictionary / Determine maximum length of name in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 20050/20050 [00:00<00:00, 488934.73it/s]\n"
     ]
    }
   ],
   "source": [
    "character_dictionary = {}\n",
    "unique_idx = 0\n",
    "max_length = -1\n",
    "for name in tqdm(names):\n",
    "    length = len(name)\n",
    "    if(length > max_length):\n",
    "        max_length = length\n",
    "    for i in range(len(name)):\n",
    "        if(name[i] not in character_dictionary.keys()):\n",
    "            character_dictionary[name[i]] = unique_idx\n",
    "            unique_idx += 1\n",
    "unique_character_no = len(character_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFFERENT UNIQUE CHARACTERS: 55\n",
      "MAXIMUM NAME LENGTH: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"DIFFERENT UNIQUE CHARACTERS: \" + str(unique_character_no))\n",
    "print(\"MAXIMUM NAME LENGTH: \" + str(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# Build inverse dictionary mapping\n",
    "inv_character_dictionary = {v: k for k, v in character_dictionary.items()}\n",
    "# Check for correctness\n",
    "print(character_dictionary['o'])\n",
    "print(inv_character_dictionary[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding and vectorization of the input names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 20050/20050 [00:00<00:00, 30879.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode and save the inputs in a matrix when each column corresponds to a different name\n",
    "vectorized_input_size = unique_character_no * max_length\n",
    "X = np.zeros((vectorized_input_size, names.shape[0]))\n",
    "for idx, name in enumerate(tqdm(names)):\n",
    "    X[:,idx] = encodeString(name, character_dictionary, max_length).flatten(order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save inputs in a file if they are not already saved\n",
    "if(not os.path.exists(save_input_path)):\n",
    "    np.save(save_input_path, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the inputs that are going to used in the validation set\n",
    "if(os.path.exists(val_ind_path)):\n",
    "    validation_indices = np.loadtxt(val_ind_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
