{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this assignment, a simple ConvNet is implemented and trained to predict the language of a surname from its spelling in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.linalg import block_diag\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ConvNet class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet:\n",
    "    \"\"\"\n",
    "    A simple ConvNet implementation with 2 convolutional layers \n",
    "    followed by a fully connected layer and a softmax output \n",
    "    layer.\n",
    "    \n",
    "    Attributes:\n",
    "        n: A list of the number of filters applied at each convo-\n",
    "            lutional layer.\n",
    "        k: A list of the width of the filter window applied in each\n",
    "            convolutional layer.\n",
    "        input_dim: dimensionality of input (number of unique characters)\n",
    "        output_dim: dimensionality of output\n",
    "        max_length: maximum number of characters in an input\n",
    "        nlen_list: List with the number of columns of the input when in its original form\n",
    "            before being vectorized, for each layer.\n",
    "        eta: initial learning rate value\n",
    "        rho: momentum constant term\n",
    "        F: list of filters/weights for each one of the convolutional\n",
    "            layers.\n",
    "        W: Weights of the fully connected layer\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n, k, output_dim, input_dim, nlen, eta = 0.001, rho = 0.9, he_init = False):\n",
    "        \"\"\"\n",
    "        Initializes the convolutional neural network\n",
    "    \n",
    "        Args:\n",
    "            he_init: When True He-initialization is performed for the weights\n",
    "            nlen: Number of columns of the input when in its original form\n",
    "            before being vectorized.\n",
    "        Raises:\n",
    "            Exception if the size of n and k is not the same.\n",
    "        \"\"\"\n",
    "        if(len(n) != len(k)):\n",
    "            raise Exception(\"The number of layers specified by <n> \" \\\n",
    "                            \"and <k> should be equal.\")\n",
    "        self.n = list(n)\n",
    "        self.k = list(k)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.max_length = nlen\n",
    "        \n",
    "        # TODO: Change He initialization for first layer due to the sparse nature of the input\n",
    "        self.F = []\n",
    "        if he_init is True:\n",
    "            self.F.append(np.random.normal(0, np.sqrt(2/nlen), (input_dim, self.k[0], self.n[0])))\n",
    "        else:\n",
    "            self.F.append(np.random.normal(0, 1, (input_dim, self.k[0], self.n[0])))\n",
    "        self.nlen_list = [nlen - self.k[0] + 1]\n",
    "        \n",
    "        for i in range(1, len(n)):\n",
    "            if he_init is True:\n",
    "                self.F.append(np.random.normal(0, np.sqrt(2/self.nlen_list[-1]), (self.n[i - 1], self.k[i], self.n[i])))\n",
    "            else:\n",
    "                self.F.append(np.random.normal(0, 1, (self.n[i - 1], self.k[i], self.n[i])))\n",
    "            self.nlen_list.append(self.nlen_list[-1] - self.k[1] + 1)\n",
    "        fsize = self.n[-1] * self.nlen_list[-1]\n",
    "        if he_init is True:\n",
    "            self.W = np.random.normal(0, np.sqrt(2/self.nlen_list[-1]), (output_dim, fsize))\n",
    "        else:\n",
    "            self.W = np.random.normal(0, 1, (output_dim, fsize))\n",
    "    \n",
    "    def softmax(self, s):\n",
    "        \"\"\"\n",
    "        Implementation of the softmax activation function\n",
    "\n",
    "        Args:\n",
    "            s: an 1xd vector of a classifier's outputs\n",
    "\n",
    "        Returns:\n",
    "            An 1xd vector with the results of softmax given the input\n",
    "            vector s.\n",
    "        \"\"\"\n",
    "        exponents = np.exp(s - np.max(s, axis = 0)) # Max subtraction for numerical stability\n",
    "        output_exp_sum = np.sum(exponents, axis = 0)\n",
    "        p = exponents / output_exp_sum\n",
    "        return p\n",
    "\n",
    "    def constructFilterMatrix(self, F, nlen):\n",
    "        \"\"\"\n",
    "        Constructs the matrix of the filters of a layer used to\n",
    "        perform the convolution by matrix multiplication.\n",
    "        \n",
    "        Args:\n",
    "            F: A N x k x nf containing the convolutional filters\n",
    "                of a certain layer where N is the height of the convo-\n",
    "                lutional filter, k is its width and nf is the number of\n",
    "                filters in the layer.\n",
    "            nlen: Number of columns in the input of that layer. \n",
    "        \n",
    "        Returns:\n",
    "            An (nlen - k + 1) * nf x nlen * N matrix that can be used to\n",
    "            perform the convolution when multiplied by the\n",
    "            vectorized input.\n",
    "        \"\"\"\n",
    "        nf = F.shape[2]\n",
    "        vec_filters = F.transpose(2,1,0).reshape(nf, F.shape[0] * F.shape[1])\n",
    "        MF_matrix = np.zeros(((nlen - F.shape[1] + 1) * nf, nlen * F.shape[0]))\n",
    "        cur_column = 0\n",
    "        # For each time the filters are applied\n",
    "        for i in range(nlen - F.shape[1] + 1):\n",
    "            # Fill in the zero slots of the MF_Matrix with the vectorized filters\n",
    "            MF_matrix[i * nf: i * nf + nf, cur_column *  F.shape[0]: cur_column *  F.shape[0] + vec_filters.shape[1]] = vec_filters\n",
    "            cur_column += 1\n",
    "        return MF_matrix\n",
    "        \n",
    "    def makeMXMatrix(self, vec_input, height, width, nf, nlen):\n",
    "        \"\"\"\n",
    "        Computes the input matrix used for the convolutions during the \n",
    "        back-propagation.\n",
    "        \n",
    "        Args:\n",
    "            vec_input: Vectorized version of the input to the convolutional\n",
    "                layer.\n",
    "            height: corresponding height of the filter\n",
    "            width: corresponding width of the filter\n",
    "            filter_no: number of filters to be applied\n",
    "            nlen: Number of columns in the input of that layer. \n",
    "        Returns:\n",
    "            A (nlen - k + 1) * filter_no x k * filter_no * height with the\n",
    "            results of the convolutions.\n",
    "        \"\"\"\n",
    "        MX_Matrix = np.zeros(((nlen - width + 1) * nf, width * nf * height))\n",
    "        cur_column = 0\n",
    "        for i in range(nlen - width + 1):\n",
    "            # Define block diagonal matrix with the inputs to be used in this convolution on the diagonal\n",
    "            MX_Matrix[i * nf : i * nf + nf, :] = \\\n",
    "                block_diag(*[vec_input[cur_column * height: cur_column * height + width * height] for j in range(nf)]) \n",
    "            cur_column += 1\n",
    "        return MX_Matrix\n",
    "    \n",
    "    def cross_entropy_loss(self, X, Y, MFs):\n",
    "        \"\"\"\n",
    "        Calculates the cross entropy loss\n",
    "        \"\"\"\n",
    "        log_X = np.multiply(Y , self.forwardPass(X, MFs)[0]).sum(axis=0)\n",
    "        log_X[log_X == 0] = np.finfo(float).eps\n",
    "        return -np.log(log_X)\n",
    "\n",
    "    \n",
    "    def computeLoss(self, X_batch, Y_batch, MFs):\n",
    "        \"\"\"\n",
    "        Computes the loss of the network given a batch of data.\n",
    "        \n",
    "        Args:\n",
    "            X_batch: NxD matrix with N data sample inputs\n",
    "            Y_batch: NxM matrix with N data sample outputs\n",
    "        \n",
    "        Returns:\n",
    "            A scalar float value corresponding to the loss.\n",
    "        \"\"\"        \n",
    "        return np.mean(self.cross_entropy_loss(X_batch, Y_batch, MFs))# + lamda * np.sum(self.W ** 2)\n",
    "\n",
    "    def computeAccuracy(self, X, y, MFs):\n",
    "        \"\"\"\n",
    "        Computes the accuracy of the network.\n",
    "\n",
    "        Args:\n",
    "            X: Input matrix\n",
    "            y: Output labels\n",
    "\n",
    "        Returns:\n",
    "            The accuracy of the network (i.e. the percentage of\n",
    "            correctly classified inputs in X).\n",
    "\n",
    "        \"\"\"\n",
    "        softmax_outputs = self.forwardPass(X, MFs)[0] # Get probability distribution of outputs\n",
    "        # Reduce to a vector of the labels with the highest probability\n",
    "        predictions = np.argmax(softmax_outputs, axis = 0)\n",
    "        accuracy = (predictions == y).mean()\n",
    "        return accuracy\n",
    "\n",
    "    def forwardPass(self, X_batch, MFs):\n",
    "        \"\"\"\n",
    "        Performs a forward pass and returns the result:\n",
    "        \n",
    "        Args:\n",
    "            X_batch: NxD matrix with N data sample inputs\n",
    "            MFs: Matrices needed to perform convolution as \n",
    "                matrix multiplication.\n",
    "            \n",
    "        Returns:\n",
    "            A matrix with the predicted one-hot representations along with the outputs\n",
    "            of the first and second layer as well as the MF matrices calculated.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply first convolutional layer to input data followed by a ReLU activation\n",
    "        X_batch1 = MFs[0].dot(X_batch)\n",
    "        X_batch1[X_batch1 < 0.0] = 0.0\n",
    "        \n",
    "        # Apply second convolutional layer to input data followed by a ReLU activation\n",
    "        X_batch2 = MFs[1].dot(X_batch1)\n",
    "        X_batch2[X_batch2 < 0.0] = 0.0\n",
    "        \n",
    "        # Apply the fully connected layer\n",
    "        output = self.W.dot(X_batch2)\n",
    "        # Apply softmax\n",
    "        P_batch = self.softmax(output)\n",
    "        return P_batch, X_batch1, X_batch2\n",
    "    \n",
    "    def backwardPass(self, Y_batch, P_batch, X_batch, X_batch1, X_batch2, MFs):\n",
    "        \"\"\"\n",
    "        Performs a backward pass and returns the gradients:\n",
    "        \n",
    "        Args:\n",
    "            Y_batch: NxM matrix with N data sample outputs\n",
    "            P_batch: Output after the softmax activation layer\n",
    "            X_batch2: Output of the second convolutional layer after the ReLU.\n",
    "            X_batch1: Output of the first convolutional layer after the ReLU.\n",
    "            X_batch: Original batch with the inputs.\n",
    "            MFs: Matrices needed to perform convolution as \n",
    "                matrix multiplication.\n",
    "            \n",
    "        Returns:\n",
    "            The gradients of the weights of each layer (i.e. grad_F1, grad_F2, grad_W).\n",
    "        \"\"\"\n",
    "        # Initialize all gradients to zero\n",
    "        grad_W = np.zeros(self.W.shape) \n",
    "        grad_F1 = np.zeros(self.F[0].shape)\n",
    "        grad_F2 = np.zeros(self.F[1].shape)\n",
    "        \n",
    "        # Compute gradient of W\n",
    "        n = Y_batch.shape[1]\n",
    "        G_batch = -(Y_batch - P_batch)\n",
    "        grad_W = G_batch.dot(X_batch2.T) / n\n",
    "        \n",
    "        \n",
    "        # Propagate gradient through fully connected layer and ReLU of 2nd layer\n",
    "        G_batch = self.W.T.dot(G_batch)\n",
    "        G_batch *= np.where(X_batch2 > 0, 1, 0)\n",
    "        \n",
    "        # Compute gradient of the second layer's filters\n",
    "        n = X_batch1.shape[1]\n",
    "        for j in range(n):\n",
    "            g_j = G_batch[:,j]\n",
    "            x_j = X_batch1[:,j]\n",
    "            MX_matrix = self.makeMXMatrix(x_j, *self.F[1].shape, self.nlen_list[0])\n",
    "            v = g_j.T.dot(MX_matrix)\n",
    "            grad_F2 += v.reshape(grad_F2.shape, order='F')\n",
    "        grad_F2 /= n\n",
    "        \n",
    "        # Propagate gradient through second convolutional layer and ReLU of 1st layer\n",
    "        G_batch = MFs[1].T.dot(G_batch)\n",
    "        G_batch *= np.where(X_batch1 > 0, 1, 0)\n",
    "        \n",
    "        # Compute gradient of the first layer's filters\n",
    "        n = X_batch.shape[1]\n",
    "        for j in range(n):\n",
    "            g_j = G_batch[:,j]\n",
    "            x_j = X_batch[:,j]\n",
    "            MX_matrix = self.makeMXMatrix(x_j, *self.F[0].shape, self.max_length)\n",
    "            v = g_j.T.dot(MX_matrix)\n",
    "            grad_F1 += v.reshape(grad_F1.shape, order='F')\n",
    "        grad_F1 /= n       \n",
    "        \n",
    "        return grad_F1, grad_F2, grad_W\n",
    "    \n",
    "\n",
    "\n",
    "    def compute_grad_num_slow(self, X_batch, Y_batch, h = 1e-6):\n",
    "        '''Centered difference gradient'''\n",
    "        # Initialize all gradients to zero\n",
    "        grad_W = np.zeros(self.W.shape) \n",
    "        grad_F1 = np.zeros(self.F[0].shape)\n",
    "        grad_F2 = np.zeros(self.F[1].shape)\n",
    "\n",
    "        MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "        MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0]))\n",
    "        \n",
    "        for j in tqdm(range(self.W.shape[0])):\n",
    "            for k in range(self.W.shape[1]):\n",
    "                self.W[j, k] -= h\n",
    "                c1 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "                self.W[j, k] += 2 * h\n",
    "                c2 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "                self.W[j, k] -= h\n",
    "                grad_W[j, k] = (c2-c1) / (2 * h)\n",
    "        \n",
    "        \n",
    "        for j in tqdm(range(self.F[1].shape[0])):\n",
    "            for k in range(self.F[1].shape[1]):\n",
    "                for i in range(self.F[1].shape[2]):\n",
    "                    self.F[1][j, k, i] -= h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c1 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[1][j, k, i]  += 2 * h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c2= self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[1][j, k, i]  -= h\n",
    "                    grad_F2[j, k, i]  = (c2-c1) / (2 * h)\n",
    "\n",
    "        \n",
    "        for j in tqdm(range(self.F[0].shape[0])):\n",
    "            for k in range(self.F[0].shape[1]):\n",
    "                for i in range(self.F[0].shape[2]):\n",
    "                    self.F[0][j, k, i]  -= h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c1 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[0][j, k, i]  += 2 * h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c2= self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[0][j, k, i]  -= h\n",
    "                    grad_F1[j, k, i] = (c2-c1) / (2 * h)\n",
    "\n",
    "                \n",
    "        return grad_F1, grad_F2, grad_W\n",
    "    \n",
    "    def miniBatchGD(self, X, Y, GDparams, verbose = False, X_val = None, Y_val = None, tol = 1e-10, n_update = 1):\n",
    "        \"\"\"\n",
    "        Implementation of mini-batch gradient descent.\n",
    "\n",
    "         Args:\n",
    "            X: Training input matrix\n",
    "            Y: Training set desired output matrix\n",
    "            GDparams: Object of the class Params with the hyperparameters\n",
    "                used for learning.\n",
    "            verbose: Prints info in each iteration about the progress of\n",
    "                training when equal to True.\n",
    "            X_val: Validation set input matrix\n",
    "            Y_val: Validation set desired output matrix\n",
    "            n_update: After each <n_update> updates the validation and training\n",
    "                accuracy and loss are computed.\n",
    "\n",
    "        Returns:\n",
    "            The following tuple is returned where the validation lists\n",
    "            are empty if no validation set is given: (training_loss_list,\n",
    "            validation_loss_list, training_acc_list, validation_acc_list).\n",
    "        \"\"\"\n",
    "        results = ([],[],[],[])\n",
    "        mini_batch_count = X.shape[0] // GDparams.n_batch\n",
    "        y = np.argmax(Y, axis = 0)\n",
    "        \n",
    "        MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "        MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0]))\n",
    "        \n",
    "        if(X_val is not None and Y_val is not None):\n",
    "            y_val = np.argmax(Y_val, axis = 0)\n",
    "        results[0].append(self.computeLoss(X, Y, MFs))\n",
    "        results[2].append(self.computeAccuracy(X, y, MFs))\n",
    "        \n",
    "        if(X_val is not None and Y_val is not None):\n",
    "            results[1].append(self.computeLoss(X_val, Y_val, MFs))\n",
    "            results[3].append(self.computeAccuracy(X_val, y_val, MFs))\n",
    "            \n",
    "        if(verbose):\n",
    "                print(\"Starting state \")\n",
    "                print(\"    Training cost: \" + str(results[0][-1]))\n",
    "                print(\"    Training accuracy: \" + str(results[2][-1]))\n",
    "                if(X_val is not None and Y_val is not None):\n",
    "                    print(\"    Validation cost: \" + str(results[1][-1]))\n",
    "                    print(\"    Validation accuracy: \" + str(results[3][-1]))\n",
    "                    \n",
    "        # If momentum is used\n",
    "        if GDparams.rho != 0.0:\n",
    "            # Create zero matrix for each parameter\n",
    "            V_W = np.zeros(self.W.shape)\n",
    "            V_F2 = np.zeros(self.F[1].shape)\n",
    "            V_F1 = np.zeros(self.F[0].shape)\n",
    "                    \n",
    "        learning_rate = GDparams.eta\n",
    "        steps = 0\n",
    "        for i in tqdm(range(GDparams.n_epochs)):\n",
    "            for j in range(mini_batch_count):\n",
    "                steps += 1\n",
    "                \n",
    "                if(j < mini_batch_count - 1):\n",
    "                    start = j * GDparams.n_batch\n",
    "                    end = start + GDparams.n_batch\n",
    "                    mini_batch_input = X[:,start:end]\n",
    "                    mini_batch_output = Y[:,start:end]\n",
    "                else:\n",
    "                    # Take the remaining samples in the last mini batch\n",
    "                    mini_batch_input = X[:,j * GDparams.n_batch:]\n",
    "                    mini_batch_output = Y[:,j * GDparams.n_batch:]\n",
    "                \n",
    "                # Construct MF Matrices\n",
    "                MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0]))\n",
    "                P_batch, X_batch1, X_batch2 = self.forwardPass(mini_batch_input, MFs)\n",
    "                grad_F1, grad_F2, grad_W = self.backwardPass(mini_batch_output, P_batch, mini_batch_input,\\\n",
    "                                                             X_batch1, X_batch2, MFs)\n",
    "\n",
    "                # Converge if all gradients are zero\n",
    "                if np.all(grad_W < tol) == 0 and np.all(grad_F1 < tol) and np.all(grad_F2 < tol):\n",
    "                    print(\"Learning converged at epoch \" + str(i))\n",
    "                    break              \n",
    "                \n",
    "                if GDparams.rho == 0.0:\n",
    "                    self.W[0] -= learning_rate * grad_W\n",
    "                    self.F[1] -= learning_rate * grad_F2\n",
    "                    self.F[0] -= learning_rate * grad_F1\n",
    "                else:\n",
    "                    V_W = GDparams.rho * V_W + learning_rate * grad_W\n",
    "                    V_F2 = GDparams.rho * V_F2 + learning_rate * grad_F2\n",
    "                    V_F1 = GDparams.rho * V_F1 + learning_rate * grad_F1\n",
    "                    self.W -= V_W\n",
    "                    self.F[1] -= V_F2\n",
    "                    self.F[0] -= V_F1\n",
    "                \n",
    "                if steps % n_update == 0:\n",
    "                    results[0].append(self.computeLoss(X, Y, MFs))\n",
    "                    results[2].append(self.computeAccuracy(X, y, MFs))\n",
    "                    if(X_val is not None and Y_val is not None):\n",
    "                        results[1].append(self.computeLoss(X_val, Y_val, MFs))\n",
    "                        results[3].append(self.computeAccuracy(X_val, y_val, MFs))\n",
    "                    if(verbose):\n",
    "                        print(\"Iteration \" + str(i))\n",
    "                        print(\"    Training cost: \" + str(results[0][-1]))\n",
    "                        print(\"    Training accuracy: \" + str(results[2][-1]))\n",
    "                        if(X_val is not None and Y_val is not None):\n",
    "                            print(\"    Validation cost: \" + str(results[1][-1]))\n",
    "                            print(\"    Validation accuracy: \" + str(results[3][-1]))\n",
    "            # Decay the learning rate\n",
    "            learning_rate *= GDparams.decay_rate\n",
    "            \n",
    "    \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    \"\"\"\n",
    "    Class containing hyperparameters used for\n",
    "    gradient descent learning.\n",
    "    \n",
    "    Attributes:\n",
    "        n_batch: Number of samples in each mini-batch.\n",
    "        eta: Learning rate\n",
    "        n_epochs: Maximum number of learning epochs.\n",
    "        decay_rate: The percentage of decay of the learning rate after each epoch, i.e.\n",
    "            a factor less than 1 by which the learning rate gets multiplied after each \n",
    "            epoch.\n",
    "        rho: percentage of use of the gradients of previous turns in learning to add momentum\n",
    "    \"\"\"\n",
    "    def __init__(self, n_batch, eta, n_epochs, decay_rate = 1.0, rho = 0.0):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.n_batch = n_batch\n",
    "        self.eta = eta\n",
    "        self.n_epochs = n_epochs\n",
    "        self.decay_rate = decay_rate\n",
    "        self.rho = rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelativeErrors(grad1, grad2):\n",
    "    \"\"\"\n",
    "    Computes the relative errors of grad_1 and grad_2 gradients\n",
    "    \"\"\"\n",
    "    abs_diff = np.absolute(grad1 - grad2) \n",
    "    abs_sum = np.absolute(grad1) + np.absolute(grad2)\n",
    "    max_elems = np.where(abs_sum > np.finfo(float).eps, abs_sum, np.finfo(float).eps)\n",
    "    relativeErrors = abs_diff / max_elems\n",
    "    return relativeErrors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeString(string, character_dictionary, max_length):\n",
    "    \"\"\"\n",
    "    One-hot encodes the character string, converting each \n",
    "    of its letters to one-hot encoded vectors and stacking\n",
    "    them from left to right. \n",
    "    \n",
    "    Args:\n",
    "        name: The string to be encoded.\n",
    "        character_dictionary: A dictionary which has a unique\n",
    "            index for each character in the alphabet used by\n",
    "            the string.\n",
    "        max_length: maximum length of the string. If the string\n",
    "            has a length less than max_length, zero columnds are\n",
    "            added as padding after the encoded character columns.\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "        A C x max_length vector with the one-hot encoded characters\n",
    "        of the string and possibly zero padding in the last columns\n",
    "        where C is the number of different characters in the alpha-\n",
    "        bet used.\n",
    "    \"\"\"\n",
    "    d = len(character_dictionary)\n",
    "    encoded_string = np.zeros((d, max_length))\n",
    "    for i in range(len(string)):\n",
    "        encoded_string[character_dictionary[string[i]],i] = 1\n",
    "    return encoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(label_id, label_no):\n",
    "    \"\"\"\n",
    "    Returns a one-hot encoded numpy vector with 1 at the index\n",
    "    of the label and 0 for each other element.\n",
    "    \n",
    "    Args:\n",
    "        label_id: Index of label.\n",
    "        label_no: Number of total labels.\n",
    "    \n",
    "    Returns:\n",
    "        A one-hot encoded vector with label_no elements.\n",
    "    \"\"\"\n",
    "    vector = np.zeros(label_no) \n",
    "    vector[label_id] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the files containing the data\n",
    "name_path = \"ascii_names.txt\"\n",
    "category_labels_path = \"category_labels.txt\"\n",
    "# Path to file used to save the inputs after their encoding\n",
    "save_input_path = \"onehot_encoded_inputs.npy\"\n",
    "# Path to file with the indices of the inputs that are going to used in the validation set\n",
    "val_ind_path = \"Validation_Inds.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "20050it [00:00, 977687.56it/s]"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "names = []\n",
    "labels = []\n",
    "if(os.path.exists(name_path)):\n",
    "    with open(name_path,\"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            entry = line.split()\n",
    "            names.append(' '.join(entry[:-1]))\n",
    "            labels.append(entry[-1])\n",
    "    f.close()\n",
    "    names = np.array(names)\n",
    "    labels = np.array(labels, dtype = int) \n",
    "else:\n",
    "    print(\"Requested file \" + name_path + \" does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Arabic\n"
     ]
    }
   ],
   "source": [
    "# Read the different class names and indices and build a dictionary\n",
    "if(os.path.exists(category_labels_path)):\n",
    "    class_names = np.loadtxt(category_labels_path, usecols = 1, dtype = str)\n",
    "    class_indices = np.loadtxt(category_labels_path, usecols = 0, dtype = int)\n",
    "    K = len(class_names)\n",
    "    class_dictionary = {}\n",
    "    for i in range(K):\n",
    "        class_dictionary[class_names[i]] = class_indices[i]\n",
    "    inv_class_dictionary = {v: k for k, v in class_dictionary.items()}\n",
    "    # Check for correctness\n",
    "    print(class_dictionary['Arabic'])\n",
    "    print(inv_class_dictionary[1])\n",
    "else: \n",
    "    print(\"Requested file \" + category_labels_path + \" does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine number of unique characters and set up dictionary / Determine maximum length of name in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                | 0/20050 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████| 20050/20050 [00:00<00:00, 431191.94it/s]"
     ]
    }
   ],
   "source": [
    "character_dictionary = {}\n",
    "unique_idx = 0\n",
    "max_length = -1\n",
    "for name in tqdm(names):\n",
    "    length = len(name)\n",
    "    if(length > max_length):\n",
    "        max_length = length\n",
    "    for i in range(len(name)):\n",
    "        if(name[i] not in character_dictionary.keys()):\n",
    "            character_dictionary[name[i]] = unique_idx\n",
    "            unique_idx += 1\n",
    "d = len(character_dictionary) # Get number of unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFFERENT UNIQUE CHARACTERS: 55\n",
      "MAXIMUM NAME LENGTH: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"DIFFERENT UNIQUE CHARACTERS: \" + str(d))\n",
    "print(\"MAXIMUM NAME LENGTH: \" + str(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# Build inverse dictionary mapping\n",
    "inv_character_dictionary = {v: k for k, v in character_dictionary.items()}\n",
    "# Check for correctness\n",
    "print(character_dictionary['o'])\n",
    "print(inv_character_dictionary[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding and vectorization of the input names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                | 0/20050 [00:00<?, ?it/s]\n",
      " 16%|█████▎                            | 3169/20050 [00:00<00:00, 31377.25it/s]\n",
      " 30%|██████████▎                       | 6114/20050 [00:00<00:00, 30418.35it/s]\n",
      " 46%|███████████████▍                  | 9123/20050 [00:00<00:00, 30257.60it/s]\n",
      " 60%|███████████████████▊             | 12045/20050 [00:00<00:00, 29999.16it/s]\n",
      " 74%|████████████████████████▍        | 14874/20050 [00:00<00:00, 29600.08it/s]\n",
      " 88%|█████████████████████████████    | 17671/20050 [00:00<00:00, 29353.26it/s]\n",
      "100%|█████████████████████████████████| 20050/20050 [00:00<00:00, 29442.21it/s]"
     ]
    }
   ],
   "source": [
    "# Encode and save the inputs in a matrix when each column corresponds to a different name\n",
    "vectorized_input_size = d * max_length\n",
    "X = np.zeros((vectorized_input_size, names.shape[0]))\n",
    "for idx, name in enumerate(tqdm(names)):\n",
    "    X[:,idx] = encodeString(name, character_dictionary, max_length).flatten(order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save inputs in a file if they are not already saved\n",
    "if(not os.path.exists(save_input_path)):\n",
    "    np.save(save_input_path, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the inputs that are going to used in the validation set\n",
    "if(os.path.exists(val_ind_path)):\n",
    "    validation_indices = np.loadtxt(val_ind_path, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for outputputs\n",
    "Y = np.array([one_hot_encoding(label - 1, K) for label in labels], order = 'F').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate data in training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard indices that do not correspond to any input\n",
    "validation_indices = validation_indices[validation_indices < X.shape[1]]\n",
    "# Take out the validation set\n",
    "X_val = X[:,validation_indices]\n",
    "X_tr = np.delete(X, validation_indices, axis = 1)\n",
    "Y_val = Y[:,validation_indices]\n",
    "Y_tr = np.delete(Y, validation_indices, axis = 1)\n",
    "#print(X.shape)\n",
    "#print(X_tr.shape)\n",
    "#print(X_val.shape)\n",
    "#print(Y.shape)\n",
    "#print(Y_tr.shape)\n",
    "#print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters & initialize the ConvNet's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_width_constants = [3, 3]\n",
    "filter_numbers = [5, 5]\n",
    "K = len(class_dictionary)\n",
    "conv_net = ConvNet(n = filter_numbers , k = filter_width_constants, output_dim = K, \\\n",
    "                   input_dim = d, nlen = max_length, he_init = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Debug based on saved filters and convolution outputs\n",
    "dictionary = loadmat(\"Debugging_files/DebugInfo\")\n",
    "x_input = dictionary['x_input'].reshape(1, -1)\n",
    "X_input = dictionary['X_input']\n",
    "F = dictionary['F']\n",
    "vecS = dictionary['vecS']\n",
    "MF_Matrix = conv_net.constructFilterMatrix(F, max_length)\n",
    "s = MF_Matrix.dot(x_input.reshape(-1, 1)).flatten()\n",
    "print(np.allclose(s, vecS.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_Matrix = conv_net.constructFilterMatrix(conv_net.F[0], max_length)\n",
    "MF_Matrix2 = conv_net.constructFilterMatrix(conv_net.F[1], conv_net.nlen_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2956de7df60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFxJJREFUeJzt3X+w3XV95/Hnm5tfEE1CCMGYpAYzmFpd5ccd0KV1BPrDGgXakSxIbXYnzu0w1mJXVqI76rjrzqYzO1V3Wu1kRJq2lh+ilJRptRlEK3Y3aiCWQJRgoBhCctUQoTJLQN77x/ne5n7vr3Nu7vfc8z1fno+ZO+d8vud7znnnnnPf95PP+X5fNzITSVL/O6nXBUiSqmFDl6SGsKFLUkPY0CWpIWzoktQQNnRJaggbuiQ1hA1dkhrChi5JDTFnNp9sYNHCnHv6ktl8SkkvAnN/HKXxktVPl8ZPPVhudcfOOKW8/9J/LY2PPntyafzCc+W577yfHr/+/ILyc78wf0xt5YfmucXls/Pj2fL9c/74s/ePPfL4jzPz9HE3jDGrDX3u6UtYveWa2XxKSQ00NrFk9Q1zS+P1n/xqabzj3OWl8Q83nVsaX7rhm6Xx9v2vLY2fGV5YGr/ib49fP/Kqcht9eu3PS+MV95Qb9qH1x0rjefsXlMbHzvx/jPXouz70L+M2TsAlF0lqCBu6JDXErC65SFIVTjqpvOZyZN28Kfc//O7yEsuCH5dv/+jpu0rjHY+vK40vOOfB0vifDr/u364vPFB+rLN+f2dpPPCSl5TGv3J9eVH9m7dfUBp/4OpbGOvycVsm5gxdkhrChi5JDeGSi6S+8wv/uzwXffjdz5bGGxfvKY1ve1t5ySX/qnwE4C9/9A9K4+W/82hp/CuL95XG/8TxJZefXPBc6baVv/Oy0vjdK79RGl/7j1eVxos2PlUav+///AfG++4E28Zzhi5JDWFDl6SGcMlFUt/Zf035ZJ1/t+rx0vjpF14ojZ/cWT6x6NgF5dvnvuxnpfHLKB9F89+/8lulcSw6fvtJzwyUbrt/7y+Uxv/l6xtL4wXPl4Y8daw8rz7nNY8y1vgtE2s7Q4+IdRGxe9TXUxHxvohYGhE7ImJfcXlqh88pSeqCyLHn0E61c8QA8DhwAfAe4EhmbomIzcCpmXn9VPdfsHZleuq/pJma953yqfg/O7N8uv3S3eVZ87FF5ftv+N27S+O7h88qjR/Z+/LSeP6K8gz+v73u+Ln/T79QPnX/43ddVhq/5jWPlcarFz5ZGn/5268vjfdfvpWxBlbs25WZg+NuGGO6a+iXAD/IzH8BLgO2Fdu30fmx75KkLphuQ78SuKm4fkZmPgFQXC6f9F6SpK7reMklIuYBB4HXZObhiDiamUtG3f5kZo5bR4+IIWAIYM6yxeet+fR11VQuqW/MOB3x/dWlI0K1CYlj0xHnzC8/VhUe3vDhypdcfhO4NzMPF+PDEbECoLgcnuhOmbk1Mwczc3Bg0cKJdpEkVWA6Df0qji+3AGwHRo7H2QjcUVVRkqTp6+g49Ig4Bfg14PdGbd4C3BoRm4DHgCuqL09SE9QpHRGqTUgcm4543a530CsdNfTMfAY4bcy2n9A66kWSVAOe+i9JDeGp/5K6rk7piFBtQuLYdMQ586o/yqVTztAlqSFs6JLUEC65SOq6OqUjQrUJiWPTEfccXEGvOEOXpIawoUtSQ7jkIqnrTt59cml8/09fURq/4/MfKI3njom7vfq3v14aj427feD+8uPNXzl53C20j7w9602PlMZTRd5+ce2O0m3rDv4uveIMXZIawoYuSQ0xrb9YNFP+xSKpf0wn8raf4m5hdiJvq9SN+FxJUo3Z0CWpITzKRdKEphN5209xt1CvyNsqOUOXpIawoUtSQ7jkImlC04m87ae4W6hX5G2VnKFLUkPY0CWpIVxykTSh6UTe9lPcLdQr8rZKHc3QI2JJRNwWEd+LiL0R8caIWBoROyJiX3F5areLlSRNrtMZ+qeAL2fmOyJiHnAK8CHgrszcEhGbgc3A9V2qU9Ism05CYj+lI0K9EhKr1HaGHhGLgDcBNwBk5rHMPApcBmwrdtsGXN6tIiVJ7XWy5PJK4EfAjRFxX0R8NiIWAmdk5hMAxeXyqR5EktRdbdMWI2IQ+L/AhZm5MyI+BTwFvDczl4za78nMHLeOHhFDwBDAnGWLz1vz6euqrF9SYTrpiFBtQqLpiN1VZdriAeBAZo6EJ9wGnAscjogVAMXl8ER3zsytmTmYmYMDixZOtIskqQJtG3pmHgJ+GBEjaTqXAA8C24GRY4U2And0pUJJUkc6PcrlvcDniyNc9gP/idYvg1sjYhPwGHBFd0qU1InppCNCtQmJpiPWQ0cNPTN3AxOt31xSbTmSpBPlqf+S1BCe+i81xHTSEaHahETTEevBGbokNYQNXZIawiUXqSGmk44I1SYkmo5YD87QJakhbOiS1BAuuUgNMZ24W6g28ta423pwhi5JDWFDl6SGaBufW6UFa1fm6i3XzNrzSXXWy7hbqDby1rjb7qoyPleS1Ads6JLUEB7lIvVIL+NuodrIW+Nu68EZuiQ1hA1dkhrCJRepR3oZdwvVRt4ad1sPztAlqSFs6JLUEC65SD3Sy7hbqDby1rjbeuiooUfEo8DTwM+B5zNzMCKWArcAa4BHgQ2Z+eRkjyFJ6q7pzNAvyszRR75uBu7KzC0RsbkYX19pdVKD9TIdEapNSDQdsR5msoZ+GbCtuL4NuHzm5UiSTlSnDT2Bf4iIXRExVGw7IzOfACgul096b0lS13WUthgRL8/MgxGxHNgBvBfYnplLRu3zZGaeOsF9h4AhgDnLFp+35tPXVVa8NNumSkjsp3REMCGxn1SatpiZB4vLYeB24HzgcESsACguhye579bMHMzMwYFFCyfaRZJUgbYNPSIWRsRLR64Dvw7sAbYDI8cxbQTu6FaRkqT2OjnK5Qzg9ogY2f+vM/PLEfFt4NaI2AQ8BlzRvTKlephOQmKd0xHBhMQmatvQM3M/8PoJtv8EuKQbRUmSps9T/yWpITz1X5qGqRIS+ykdEUxIbCJn6JLUEDZ0SWoIl1ykaZgqIbGf0hHBhMQmcoYuSQ1hQ5ekhnDJRZqGqSJv+ynuFoy8bSJn6JLUEDZ0SWqIjuJzq7Jg7cpcveWaWXs+aaq4W6g28ta4W3VLpfG5kqT6s6FLUkN4lIsabTpxtzCzyFvjbtVrztAlqSFs6JLUEC65qNGmiruFaiNvjbtVrzlDl6SGsKFLUkO45KJGmyruFqqNvDXuVr3W8Qw9IgYi4r6IuLMYnxkROyNiX0TcEhFTHw8mSeqq6czQrwX2AiMZcn8EfCIzb46IPwM2AZ+puD5pRqZKR4RqExJNR1SvdTRDj4hVwHrgs8U4gIuB24pdtgGXd6NASVJnOl1y+STwAWBkQfE04GhmjqzyHQBWVlybJGka2i65RMTbgOHM3BURbx7ZPMGuE8Y2RsQQMAQwZ9niEyxTLxZVpyO+/erJ0xEBjpw7dULiF268qDQel5A46uEPrS/X+pGb3lkaj01HnLusPH7ocPnf8hDl8dzTyvuv+4ZLLCrrZA39QuDSiHgrsIDWGvongSURMaeYpa8CDk5058zcCmyFVnxuJVVLksZpu+SSmR/MzFWZuQa4EvhqZl4N3A2MpAFtBO7oWpWSpLZmchz69cDNEfFx4D7ghmpK0ovZbKYjQrUJiaYjqtem1dAz82vA14rr+4Hzqy9JknQiPPVfkhrCU/9VK7OZjgjVJiSajqhec4YuSQ1hQ5ekhnDJRbUym+mIUG1CoumI6jVn6JLUEDZ0SWoIl1xUK7MZdwvVRt4ad6tec4YuSQ1hQ5ekhogcm1faRQvWrszVW66ZtedT91Udd3vphqnjbp8Znjru9siryquI4+Ju7ykfRXNo/bHSeN7+8hLL2MjbOfM9GUiz7+ENH96VmYPt9nOGLkkNYUOXpIbwKBfNSD/H3YKRt2oWZ+iS1BA2dElqCJdcNCP9HHcLRt6qWZyhS1JD2NAlqSFcctGM9HPcLRh5q2ZpO0OPiAUR8a2I+G5EPBARHyu2nxkROyNiX0TcEhFTH68mSeqqTmbozwIXZ+a/RsRc4J6I+HvgPwOfyMybI+LPgE3AZ7pYq2qon9MRwYRENUvbGXq2jJx9Mbf4SuBi4LZi+zbg8q5UKEnqSEcfikbEQETsBoaBHcAPgKOZObICeQBY2Z0SJUmd6OhD0cz8OXB2RCwBbgdePdFuE903IoaAIYA5yxafYJmqUpUJiW+/eup0xCPnTp2O+IUbLyqNx6Ujlh+eQ+vLtX7kpneWxmPTEecuK48fOlz+tzxEeTz3tPL+677hEov6x7QOW8zMo8DXgDcASyJi5BfCKuDgJPfZmpmDmTk4sGjhRLtIkirQyVEupxczcyLiZOBXgb3A3cBIUtFG4I5uFSlJaq+TJZcVwLaIGKD1C+DWzLwzIh4Ebo6IjwP3ATd0sU5VqMqERNMRpfpo29Az85+BcybYvh84vxtFSZKmz1P/JakhPPX/RajKhETTEaX6cIYuSQ1hQ5ekhnDJ5UWoyoRE0xGl+nCGLkkNYUOXpIZwyeVFqMrIW+Nupfpwhi5JDWFDl6SGiBybpdpFC9auzNVbrpm152uKKuNuAS7dMHXk7TPDU0feHnnV8ZW6cXG395SPoDm0/lhpPG9/eYllbNztnPmeCCSN9fCGD+/KzMF2+zlDl6SGsKFLUkN4lEsfqDLuFqqNvDXuVqoPZ+iS1BA2dElqCJdc+kCVcbdQbeStcbdSfThDl6SGsKFLUkO45NIHqoy7hWojb427leqj7Qw9IlZHxN0RsTciHoiIa4vtSyNiR0TsKy5P7X65kqTJdDJDfx54f2beGxEvBXZFxA7gPwJ3ZeaWiNgMbAau716pL15VpiNCtQmJpiNK9dF2hp6ZT2TmvcX1p4G9wErgMmBbsds24PJuFSlJam9aH4pGxBrgHGAncEZmPgGtpg8sn/yekqRu6zhtMSJeAnwd+B+Z+aWIOJqZS0bd/mRmjltHj4ghYAhgzrLF56359HXVVF5jdU5HhGoTEk1HlLqv0rTFiJgLfBH4fGZ+qdh8OCJWFLevAIYnum9mbs3MwcwcHFi0cKJdJEkV6OQolwBuAPZm5h+Pumk7MHKM2kbgjurLkyR1qpOjXC4E3gXcHxG7i20fArYAt0bEJuAx4IrulNh/6pyOCNUmJJqOKNVH24aemfcAMcnNl1RbjiTpRHnqvyQ1hKf+d0Gd0xGh2oRE0xGl+nCGLkkNYUOXpIZwyaUL6pyOCNUmJJqOKNWHM3RJaggbuiQ1hEsuXVDnuFuoNvLWuFupPpyhS1JD2NAlqSE6js+twoK1K3P1lmtm7fmmYyaRt/0UdwtG3kr9ptL4XElS/dnQJakhPMqlMJPI236KuwUjb6WmcoYuSQ1hQ5ekhnDJpTCTyNt+irsFI2+lpnKGLkkNYUOXpIZwyaUwk8jbfoq7BSNvpaZqO0OPiM9FxHBE7Bm1bWlE7IiIfcXlqd0tU5LUTicz9D8H/gT4i1HbNgN3ZeaWiNhcjK+vvrzZM5OExH5KRwQTEqWmajtDz8x/BI6M2XwZsK24vg24vOK6JEnTdKIfip6RmU8AFJfL2+wvSeqyrn8oGhFDwBDAnGWLK3vcmaQjwviExLdfPXVC4pFzJ09I/MKNF5VuG5eOWH5oDq0v1/qRm95ZGo9NR5y7rDx+6HD53/LQmN+nc08r77/uGy6xSC8GJzpDPxwRKwCKy+HJdszMrZk5mJmDA4sWTrabJGmGTrShbwdGjp3bCNxRTTmSpBPVdsklIm4C3gwsi4gDwEeBLcCtEbEJeAy4optFTmQm6YhQbUKi6YiS6qBtQ8/Mqya56ZKKa5EkzYCn/ktSQ/Ttqf8zSUeEahMSTUeUVAfO0CWpIWzoktQQfbvkMpN0RKg2IdF0REl14AxdkhrChi5JDdG3Sy4zibuFaiNvjbuVVAfO0CWpIWzoktQQkWNzaLtowdqVuep/XgPMPO720g1Tx90+Mzx53C3AkVeVV5vGRd7eUz6K5tD6Y6XxvP3Hl1nGxt3Ome+JQJKq8/CGD+/KzMF2+zlDl6SGsKFLUkPM+lEuI7G3vYy7hWojb427lVQHztAlqSFs6JLUELO65DJv+HjsbS/jbqHayFvjbiXVgTN0SWqIWZ2hP3v68ZTEXqYjQrUJiaYjSqoDZ+iS1BAzaugR8ZaI+H5EPBwRm6sqSpI0fSe85BIRA8CfAr8GHAC+HRHbM/PBye5z0jMn/VtKYi/TEaHahETTESXVwUxm6OcDD2fm/sw8BtwMXNbmPpKkLplJQ18J/HDU+ECxTZLUAyecthgRVwC/kZnvLsbvAs7PzPeO2W8IGCqGrwXKB5zXxzLgx2336p0612dtJ67O9dW5Nqh3fVXX9orMPL3dTjM5bPEAsHrUeBVwcOxOmbkV2AoQEd/pJAKyF+pcG9S7Pms7cXWur861Qb3r61VtM1ly+TZwVkScGRHzgCuB7dWUJUmarhOeoWfm8xHx+8BXgAHgc5n5QGWVSZKmZUZnimbm3wF/N427bJ3J83VZnWuDetdnbSeuzvXVuTaod309qW1W/wSdJKl7PPVfkhpiVhp63SICIuJzETEcEXtGbVsaETsiYl9xeWqPalsdEXdHxN6IeCAirq1LfRGxICK+FRHfLWr7WLH9zIjYWdR2S/Ehec9ExEBE3BcRd9apvoh4NCLuj4jdEfGdYlvPX9dR9S2JiNsi4nvF+++NdagvItYV37ORr6ci4n11qK2o7w+Ln4c9EXFT8XPSk/dc1xv6qIiA3wR+CbgqIn6p28/bxp8DbxmzbTNwV2aeBdxVjHvheeD9mflq4A3Ae4rvVx3qexa4ODNfD5wNvCUi3gD8EfCJorYngU09qG20a4G9o8Z1qu+izDx71CFtdXhdR3wK+HJm/iLwelrfw57Xl5nfL75nZwPnAc8At9ehtohYCfwBMJiZr6V1gMiV9Oo9l5ld/QLeCHxl1PiDwAe7/bwd1LUG2DNq/H1gRXF9BfD9XtdY1HIHrbycWtUHnALcC1xA6wSKORO93j2oaxWtH+6LgTuBqEt9wKPAsjHbavG6AouARyg+V6tbfaPq+XXgm3WpjeNnzC+ldZDJncBv9Oo9NxtLLv0SEXBGZj4BUFwub7N/10XEGuAcYCc1qa9YztgNDAM7gB8ARzNzJDG+16/vJ4EPACMB+qdRn/oS+IeI2FWcQQ01eV2BVwI/Am4slqs+GxELa1TfiCuBm4rrPa8tMx8H/hfwGPAE8FNgFz16z81GQ48JtnloTRsR8RLgi8D7MvOpdvvPlsz8ebb+67uKVkDbqyfabXaraomItwHDmblr9OYJdu3V++/CzDyX1vLjeyLiTT2qYyJzgHOBz2TmOcDP6O3yzzjFOvSlwBd6XcuIYt3+MuBM4OXAQlqv71iz8p6bjYbeUURADRyOiBUAxeVwrwqJiLm0mvnnM/NLdasPIDOPAl+jtc6/JCJGzmno5et7IXBpRDxKK/3zYloz9lrUl5kHi8thWmvA51Of1/UAcCAzdxbj22g1+LrUB61GeW9mHi7GdajtV4FHMvNHmfkc8CXg39Oj99xsNPR+iQjYDoz83bmNtNauZ11EBHADsDcz/3jUTT2vLyJOj4glxfWTab2Z9wJ3A+/oZW0AmfnBzFyVmWtovc++mplX16G+iFgYES8duU5rLXgPNXhdATLzEPDDiFhXbLoEeJCa1Fe4iuPLLVCP2h4D3hARpxQ/uyPft96852bpg4O3Ag/RWm/9r7P9wcUE9dxEa73rOVozk0201lrvAvYVl0t7VNsv0/rv2T8Du4uvt9ahPuB1wH1FbXuAjxTbXwl8C3iY1n+H59fgNX4zcGdd6itq+G7x9cDIz0EdXtdRNZ4NfKd4ff8GOLUu9dH6EP4nwOJR2+pS28eA7xU/E38JzO/Ve84zRSWpITxTVJIawoYuSQ1hQ5ekhrChS1JD2NAlqSFs6JLUEDZ0SWoIG7okNcT/B5nmdXHJI56QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2956ddb76d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the mf_matrix to confirm that it is block diagonal\n",
    "plt.pcolormesh(MF_Matrix)\n",
    "plt.show()\n",
    "plt.pcolormesh(MF_Matrix2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "MX_Matrix = conv_net.makeMXMatrix((X[:,17513]), *conv_net.F[0].shape, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Debugging for make MX and make MF functions (s1 and s2 should be equal)\n",
    "s1 = MX_Matrix.dot(conv_net.F[0].flatten('F').reshape(-1, 1))\n",
    "s2 = MF_Matrix.dot(X[:,17513].reshape(-1, 1))\n",
    "print(np.allclose(s1,s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct MF Matrices\n",
    "MFs = [conv_net.constructFilterMatrix(conv_net.F[0], conv_net.max_length)]\n",
    "MFs.append(conv_net.constructFilterMatrix(conv_net.F[1], conv_net.nlen_list[0]))\n",
    "P_batch, X_batch1, X_batch2 = conv_net.forwardPass(X[:,:100], MFs)\n",
    "grad_F1, grad_F2, grad_W = conv_net.backwardPass(Y[:,:100], P_batch, X[:,:100], X_batch1, X_batch2, MFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                   | 0/18 [00:00<?, ?it/s]\n",
      "  6%|██▍                                        | 1/18 [00:00<00:02,  8.40it/s]\n",
      " 11%|████▊                                      | 2/18 [00:00<00:01,  8.74it/s]\n",
      " 17%|███████▏                                   | 3/18 [00:00<00:01,  8.95it/s]\n",
      " 22%|█████████▌                                 | 4/18 [00:00<00:01,  8.91it/s]\n",
      " 28%|███████████▉                               | 5/18 [00:00<00:01,  8.93it/s]\n",
      " 33%|██████████████▎                            | 6/18 [00:00<00:01,  8.74it/s]\n",
      " 39%|████████████████▋                          | 7/18 [00:00<00:01,  8.61it/s]\n",
      " 44%|███████████████████                        | 8/18 [00:00<00:01,  8.63it/s]\n",
      " 50%|█████████████████████▌                     | 9/18 [00:01<00:01,  8.73it/s]\n",
      " 56%|███████████████████████▎                  | 10/18 [00:01<00:00,  8.77it/s]\n",
      " 61%|█████████████████████████▋                | 11/18 [00:01<00:00,  8.81it/s]\n",
      " 67%|████████████████████████████              | 12/18 [00:01<00:00,  8.84it/s]\n",
      " 72%|██████████████████████████████▎           | 13/18 [00:01<00:00,  8.88it/s]\n",
      " 78%|████████████████████████████████▋         | 14/18 [00:01<00:00,  8.91it/s]\n",
      " 83%|███████████████████████████████████       | 15/18 [00:01<00:00,  8.96it/s]\n",
      " 89%|█████████████████████████████████████▎    | 16/18 [00:01<00:00,  9.00it/s]\n",
      " 94%|███████████████████████████████████████▋  | 17/18 [00:01<00:00,  9.02it/s]\n",
      "100%|██████████████████████████████████████████| 18/18 [00:01<00:00,  9.06it/s]\n",
      "\n",
      "  0%|                                                    | 0/5 [00:00<?, ?it/s]\n",
      " 80%|███████████████████████████████████▏        | 4/5 [00:00<00:00, 39.22it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 37.74it/s]\n",
      "  0%|                                                   | 0/55 [00:00<?, ?it/s]\n",
      "  7%|███▏                                       | 4/55 [00:00<00:01, 38.83it/s]\n",
      " 15%|██████▎                                    | 8/55 [00:00<00:01, 38.37it/s]D:\\Anaconda3\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "\n",
      " 22%|█████████▏                                | 12/55 [00:00<00:01, 36.75it/s]\n",
      " 29%|████████████▏                             | 16/55 [00:00<00:01, 36.91it/s]\n",
      " 36%|███████████████▎                          | 20/55 [00:00<00:00, 37.28it/s]\n",
      " 44%|██████████████████▎                       | 24/55 [00:00<00:00, 37.59it/s]\n",
      " 51%|█████████████████████▍                    | 28/55 [00:00<00:00, 37.71it/s]\n",
      " 58%|████████████████████████▍                 | 32/55 [00:00<00:00, 37.85it/s]\n",
      " 67%|████████████████████████████▎             | 37/55 [00:00<00:00, 38.26it/s]\n",
      " 76%|████████████████████████████████          | 42/55 [00:01<00:00, 38.62it/s]\n",
      " 84%|███████████████████████████████████▏      | 46/55 [00:01<00:00, 38.69it/s]\n",
      " 91%|██████████████████████████████████████▏   | 50/55 [00:01<00:00, 38.77it/s]\n",
      " 98%|█████████████████████████████████████████▏| 54/55 [00:01<00:00, 38.82it/s]\n",
      "100%|██████████████████████████████████████████| 55/55 [00:01<00:00, 38.70it/s]"
     ]
    }
   ],
   "source": [
    "grad_F1_approx, grad_F2_approx, grad_W_approx = conv_net.compute_grad_num_slow(X[:,:100], Y[:,:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.165441154216389e-06\n",
      "6.400764004340535e-07\n",
      "2.3077113589892306e-06\n",
      "8.756918632779195e-08\n",
      "2.3778036353764807e-08\n",
      "6.320978737973386e-08\n"
     ]
    }
   ],
   "source": [
    "errors1 = getRelativeErrors(grad_F1, grad_F1_approx)\n",
    "errors2 = getRelativeErrors(grad_F2, grad_F2_approx)\n",
    "errors3 = getRelativeErrors(grad_W, grad_W_approx)\n",
    "print(np.max(errors1))\n",
    "print(np.max(errors2))\n",
    "print(np.max(errors3))\n",
    "\n",
    "print(np.mean(errors1))\n",
    "print(np.mean(errors2))\n",
    "print(np.mean(errors3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using mini-batch gradient descent with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state \n",
      "    Training cost: 5.8126829642800315\n",
      "    Training accuracy: 0.03507702537958551\n",
      "    Validation cost: 5.860580986991063\n",
      "    Validation accuracy: 0.03093812375249501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "    Training cost: 5.616160170690379\n",
      "    Training accuracy: 0.04361077247035354\n",
      "    Validation cost: 5.668642054322005\n",
      "    Validation accuracy: 0.04341317365269461\n",
      "Iteration 0\n",
      "    Training cost: 5.478315595207743\n",
      "    Training accuracy: 0.06594259115593483\n",
      "    Validation cost: 5.528162662511577\n",
      "    Validation accuracy: 0.06487025948103792\n",
      "Iteration 0\n",
      "    Training cost: 6.4947515282928805\n",
      "    Training accuracy: 0.0933724925191178\n",
      "    Validation cost: 6.551942308488295\n",
      "    Validation accuracy: 0.08582834331337326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "    Training cost: 8.946437157311115\n",
      "    Training accuracy: 0.10018840740330268\n",
      "    Validation cost: 9.027503599457537\n",
      "    Validation accuracy: 0.0968063872255489\n",
      "Iteration 0\n",
      "    Training cost: 11.89644440497915\n",
      "    Training accuracy: 0.10018840740330268\n",
      "    Validation cost: 12.001525778054027\n",
      "    Validation accuracy: 0.09630738522954092\n",
      "Iteration 0\n",
      "    Training cost: 14.793433427936996\n",
      "    Training accuracy: 0.10013299346115483\n",
      "    Validation cost: 14.914158918161952\n",
      "    Validation accuracy: 0.09630738522954092\n",
      "Iteration 0\n",
      "    Training cost: 17.537160589914887\n",
      "    Training accuracy: 0.10013299346115483\n",
      "    Validation cost: 17.670896262151096\n",
      "    Validation accuracy: 0.09630738522954092\n",
      "Iteration 0\n",
      "    Training cost: 20.12718281980613\n",
      "    Training accuracy: 0.10013299346115483\n",
      "    Validation cost: 20.272313181957408\n",
      "    Validation accuracy: 0.09630738522954092\n",
      "Iteration 0\n",
      "    Training cost: 22.565840963501742\n",
      "    Training accuracy: 0.10013299346115483\n",
      "    Validation cost: 22.72330863530131\n",
      "    Validation accuracy: 0.09630738522954092\n",
      "Iteration 0\n",
      "    Training cost: 21.834675825796094\n",
      "    Training accuracy: 0.10013299346115483\n",
      "    Validation cost: 22.016407412405115\n",
      "    Validation accuracy: 0.09630738522954092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 20%|████████▌                                  | 1/5 [04:05<16:20, 245.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "    Training cost: 13.590286279144513\n",
      "    Training accuracy: 0.10013299346115483\n",
      "    Validation cost: 13.779206618916348\n",
      "    Validation accuracy: 0.09630738522954092\n",
      "Iteration 1\n",
      "    Training cost: 8.556701219894686\n",
      "    Training accuracy: 0.10107503047766818\n",
      "    Validation cost: 8.712131824018352\n",
      "    Validation accuracy: 0.0968063872255489\n",
      "Iteration 1\n",
      "    Training cost: 5.700652977465839\n",
      "    Training accuracy: 0.10905463814695777\n",
      "    Validation cost: 5.812498464074787\n",
      "    Validation accuracy: 0.10578842315369262\n",
      "Iteration 1\n",
      "    Training cost: 4.19692993927948\n",
      "    Training accuracy: 0.12540175108057186\n",
      "    Validation cost: 4.272073184435518\n",
      "    Validation accuracy: 0.12275449101796407\n",
      "Iteration 1\n",
      "    Training cost: 3.454039273359891\n",
      "    Training accuracy: 0.14507370054305663\n",
      "    Validation cost: 3.5160284430861948\n",
      "    Validation accuracy: 0.13822355289421157\n",
      "Iteration 1\n",
      "    Training cost: 3.1163144930156714\n",
      "    Training accuracy: 0.16114374376593152\n",
      "    Validation cost: 3.168817687311534\n",
      "    Validation accuracy: 0.15219560878243513\n",
      "Iteration 1\n",
      "    Training cost: 2.9594934584613224\n",
      "    Training accuracy: 0.17233736007979608\n",
      "    Validation cost: 3.0080498304843686\n",
      "    Validation accuracy: 0.16417165668662675\n",
      "Iteration 1\n",
      "    Training cost: 2.897364472278841\n",
      "    Training accuracy: 0.18042779563338135\n",
      "    Validation cost: 2.946511542419955\n",
      "    Validation accuracy: 0.16766467065868262\n",
      "Iteration 1\n",
      "    Training cost: 2.904603150938135\n",
      "    Training accuracy: 0.1859691898481658\n",
      "    Validation cost: 2.9576065336150914\n",
      "    Validation accuracy: 0.17415169660678642\n",
      "Iteration 1\n",
      "    Training cost: 2.9090864654851067\n",
      "    Training accuracy: 0.19666408068269978\n",
      "    Validation cost: 2.9699922733174744\n",
      "    Validation accuracy: 0.18463073852295409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|█████████████████▏                         | 2/5 [08:18<12:28, 249.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2\n",
      "    Training cost: 2.8802967918955127\n",
      "    Training accuracy: 0.20835642247589495\n",
      "    Validation cost: 2.9461804601187778\n",
      "    Validation accuracy: 0.19461077844311378\n",
      "Iteration 2\n",
      "    Training cost: 2.9040797883209635\n",
      "    Training accuracy: 0.21711182533525436\n",
      "    Validation cost: 2.976834024491103\n",
      "    Validation accuracy: 0.2025948103792415\n",
      "Iteration 2\n",
      "    Training cost: 2.979224068584311\n",
      "    Training accuracy: 0.22209908012856033\n",
      "    Validation cost: 3.060985415691254\n",
      "    Validation accuracy: 0.2030938123752495\n",
      "Iteration 2\n",
      "    Training cost: 3.1045936576571695\n",
      "    Training accuracy: 0.22636595367394435\n",
      "    Validation cost: 3.1972430145854953\n",
      "    Validation accuracy: 0.2055888223552894\n",
      "Iteration 2\n",
      "    Training cost: 3.2705221144446113\n",
      "    Training accuracy: 0.22686467915327496\n",
      "    Validation cost: 3.3748364769004944\n",
      "    Validation accuracy: 0.2055888223552894\n",
      "Iteration 2\n",
      "    Training cost: 3.4732052653457495\n",
      "    Training accuracy: 0.22426022387232628\n",
      "    Validation cost: 3.589696247309711\n",
      "    Validation accuracy: 0.20459081836327345\n",
      "Iteration 2\n",
      "    Training cost: 3.701473669856317\n",
      "    Training accuracy: 0.2209353873434556\n",
      "    Validation cost: 3.828996889740491\n",
      "    Validation accuracy: 0.20159680638722555\n",
      "Iteration 2\n",
      "    Training cost: 3.9460646882943413\n",
      "    Training accuracy: 0.21644685802948022\n",
      "    Validation cost: 4.084565764856494\n",
      "    Validation accuracy: 0.20059880239520958\n",
      "Iteration 2\n",
      "    Training cost: 4.199330712822953\n",
      "    Training accuracy: 0.21273412390557464\n",
      "    Validation cost: 4.348324071606906\n",
      "    Validation accuracy: 0.19610778443113772\n",
      "Iteration 2\n",
      "    Training cost: 4.19543159202742\n",
      "    Training accuracy: 0.23573090989693007\n",
      "    Validation cost: 4.353858189697139\n",
      "    Validation accuracy: 0.2150698602794411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▊                 | 3/5 [12:30<08:20, 250.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3\n",
      "    Training cost: 3.9216797862081414\n",
      "    Training accuracy: 0.259614318962651\n",
      "    Validation cost: 4.077914451847996\n",
      "    Validation accuracy: 0.2375249500998004\n",
      "Iteration 3\n",
      "    Training cost: 3.7105271469206764\n",
      "    Training accuracy: 0.28089327274742326\n",
      "    Validation cost: 3.864676778899558\n",
      "    Validation accuracy: 0.25998003992015967\n",
      "Iteration 3\n",
      "    Training cost: 3.5496872830673323\n",
      "    Training accuracy: 0.29912445971406404\n",
      "    Validation cost: 3.7022385800533013\n",
      "    Validation accuracy: 0.28043912175648705\n",
      "Iteration 3\n",
      "    Training cost: 3.4293435863396398\n",
      "    Training accuracy: 0.3142524659204256\n",
      "    Validation cost: 3.5807563661878175\n",
      "    Validation accuracy: 0.29291417165668665\n",
      "Iteration 3\n",
      "    Training cost: 3.342250824145221\n",
      "    Training accuracy: 0.32494735675495956\n",
      "    Validation cost: 3.492960172515444\n",
      "    Validation accuracy: 0.3073852295409182\n",
      "Iteration 3\n",
      "    Training cost: 3.2832740701242042\n",
      "    Training accuracy: 0.334755624515128\n",
      "    Validation cost: 3.433743662596218\n",
      "    Validation accuracy: 0.3193612774451098\n",
      "Iteration 3\n",
      "    Training cost: 3.2457247536963143\n",
      "    Training accuracy: 0.3405740884406517\n",
      "    Validation cost: 3.3962899266299873\n",
      "    Validation accuracy: 0.32435129740518964\n",
      "Iteration 3\n",
      "    Training cost: 3.2267499566663\n",
      "    Training accuracy: 0.3445084783331486\n",
      "    Validation cost: 3.3777311741397478\n",
      "    Validation accuracy: 0.3313373253493014\n",
      "Iteration 3\n",
      "    Training cost: 3.222158573238522\n",
      "    Training accuracy: 0.3459492408289926\n",
      "    Validation cost: 3.373842931145812\n",
      "    Validation accuracy: 0.3328343313373254\n",
      "Iteration 3\n",
      "    Training cost: 3.1451068096447545\n",
      "    Training accuracy: 0.3599689681923972\n",
      "    Validation cost: 3.2972696150118077\n",
      "    Validation accuracy: 0.3458083832335329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████████▍        | 4/5 [16:35<04:08, 248.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4\n",
      "    Training cost: 2.985456359892642\n",
      "    Training accuracy: 0.37060844508478336\n",
      "    Validation cost: 3.130805012332317\n",
      "    Validation accuracy: 0.3522954091816367\n",
      "Iteration 4\n",
      "    Training cost: 2.8661435796114536\n",
      "    Training accuracy: 0.3785880527540729\n",
      "    Validation cost: 3.0058518246238304\n",
      "    Validation accuracy: 0.36227544910179643\n",
      "Iteration 4\n",
      "    Training cost: 2.779927525286514\n",
      "    Training accuracy: 0.3829657541837526\n",
      "    Validation cost: 2.915085107906686\n",
      "    Validation accuracy: 0.3687624750499002\n",
      "Iteration 4\n",
      "    Training cost: 2.7216476762979687\n",
      "    Training accuracy: 0.38435110273744877\n",
      "    Validation cost: 2.853197717969333\n",
      "    Validation accuracy: 0.3662674650698603\n",
      "Iteration 4\n",
      "    Training cost: 2.6866594194128157\n",
      "    Training accuracy: 0.3829103402416048\n",
      "    Validation cost: 2.8153443871809483\n",
      "    Validation accuracy: 0.36327345309381237\n",
      "Iteration 4\n",
      "    Training cost: 2.6715713268762307\n",
      "    Training accuracy: 0.37964091765488195\n",
      "    Validation cost: 2.7982536851065483\n",
      "    Validation accuracy: 0.3597804391217565\n",
      "Iteration 4\n",
      "    Training cost: 2.6727274331887028\n",
      "    Training accuracy: 0.373933281613654\n",
      "    Validation cost: 2.79825337898527\n",
      "    Validation accuracy: 0.35479041916167664\n",
      "Iteration 4\n",
      "    Training cost: 2.6880861494758537\n",
      "    Training accuracy: 0.3681148176881303\n",
      "    Validation cost: 2.81326656702751\n",
      "    Validation accuracy: 0.3463073852295409\n",
      "Iteration 4\n",
      "    Training cost: 2.71501056286702\n",
      "    Training accuracy: 0.3621301119361631\n",
      "    Validation cost: 2.840453517562831\n",
      "    Validation accuracy: 0.3388223552894212\n",
      "Iteration 4\n",
      "    Training cost: 2.703522433584991\n",
      "    Training accuracy: 0.36362628837415495\n",
      "    Validation cost: 2.829360860429681\n",
      "    Validation accuracy: 0.34181636726546905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 5/5 [20:39<00:00, 247.86s/it]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rho = 0.9\n",
    "epochs = 5\n",
    "mini_batch_size = 100\n",
    "decay_rate = 0.95\n",
    "eta = 0.05\n",
    "n_update = 500\n",
    "np.random.seed(0)\n",
    "\n",
    "filter_width_constants = [5, 3]\n",
    "filter_numbers = [20, 20]\n",
    "K = len(class_dictionary)\n",
    "conv_net = ConvNet(n = filter_numbers , k = filter_width_constants, output_dim = K, \\\n",
    "                   input_dim = d, nlen = max_length, he_init = True)\n",
    "\n",
    "GDparams = Params(mini_batch_size, eta, epochs, decay_rate, rho)\n",
    "results = conv_net.miniBatchGD(X_tr, Y_tr, GDparams, verbose = True, X_val = X_val, Y_val = Y_val, tol = 1e-10, n_update = n_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
