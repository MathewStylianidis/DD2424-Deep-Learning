{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this assignment, a simple ConvNet is implemented and trained to predict the language of a surname from its spelling in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.linalg import block_diag\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ConvNet class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet:\n",
    "    \"\"\"\n",
    "    A simple ConvNet implementation with 2 convolutional layers \n",
    "    followed by a fully connected layer and a softmax output \n",
    "    layer.\n",
    "    \n",
    "    Attributes:\n",
    "        n: A list of the number of filters applied at each convo-\n",
    "            lutional layer.\n",
    "        k: A list of the width of the filter window applied in each\n",
    "            convolutional layer.\n",
    "        input_dim: dimensionality of input (number of unique characters)\n",
    "        output_dim: dimensionality of output\n",
    "        max_length: maximum number of characters in an input\n",
    "        nlen_list: List with the number of columns of the input when in its original form\n",
    "            before being vectorized, for each layer.\n",
    "        eta: initial learning rate value\n",
    "        rho: momentum constant term\n",
    "        F: list of filters/weights for each one of the convolutional\n",
    "            layers.\n",
    "        W: Weights of the fully connected layer\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n, k, output_dim, input_dim, nlen, eta = 0.001, rho = 0.9, he_init = False):\n",
    "        \"\"\"\n",
    "        Initializes the convolutional neural network\n",
    "    \n",
    "        Args:\n",
    "            he_init: When True He-initialization is performed for the weights\n",
    "            nlen: Number of columns of the input when in its original form\n",
    "            before being vectorized.\n",
    "        Raises:\n",
    "            Exception if the size of n and k is not the same.\n",
    "        \"\"\"\n",
    "        if(len(n) != len(k)):\n",
    "            raise Exception(\"The number of layers specified by <n> \" \\\n",
    "                            \"and <k> should be equal.\")\n",
    "        self.n = list(n)\n",
    "        self.k = list(k)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.max_length = nlen\n",
    "        \n",
    "        # TODO: Change He initialization for first layer due to the sparse nature of the input\n",
    "        self.F = []\n",
    "        if he_init is True:\n",
    "            self.F.append(np.random.normal(0, np.sqrt(2/nlen), (input_dim, self.k[0], self.n[0])))\n",
    "        else:\n",
    "            self.F.append(np.random.normal(0, 1, (input_dim, self.k[0], self.n[0])))\n",
    "        self.nlen_list = [nlen - self.k[0] + 1]\n",
    "        \n",
    "        for i in range(1, len(n)):\n",
    "            if he_init is True:\n",
    "                self.F.append(np.random.normal(0, np.sqrt(2/self.nlen_list[-1]), (self.n[i - 1], self.k[i], self.n[i])))\n",
    "            else:\n",
    "                self.F.append(np.random.normal(0, 1, (self.n[i - 1], self.k[i], self.n[i])))\n",
    "            self.nlen_list.append(self.nlen_list[-1] - self.k[1] + 1)\n",
    "        fsize = self.n[-1] * self.nlen_list[-1]\n",
    "        if he_init is True:\n",
    "            self.W = np.random.normal(0, np.sqrt(2/self.nlen_list[-1]), (output_dim, fsize))\n",
    "        else:\n",
    "            self.W = np.random.normal(0, 1, (output_dim, fsize))\n",
    "    \n",
    "    def softmax(self, s):\n",
    "        \"\"\"\n",
    "        Implementation of the softmax activation function\n",
    "\n",
    "        Args:\n",
    "            s: an 1xd vector of a classifier's outputs\n",
    "\n",
    "        Returns:\n",
    "            An 1xd vector with the results of softmax given the input\n",
    "            vector s.\n",
    "        \"\"\"\n",
    "        exponents = np.exp(s - np.max(s, axis = 0)) # Max subtraction for numerical stability\n",
    "        output_exp_sum = np.sum(exponents, axis = 0)\n",
    "        p = exponents / output_exp_sum\n",
    "        return p\n",
    "\n",
    "    def constructFilterMatrix(self, F, nlen):\n",
    "        \"\"\"\n",
    "        Constructs the matrix of the filters of a layer used to\n",
    "        perform the convolution by matrix multiplication.\n",
    "        \n",
    "        Args:\n",
    "            F: A N x k x nf containing the convolutional filters\n",
    "                of a certain layer where N is the height of the convo-\n",
    "                lutional filter, k is its width and nf is the number of\n",
    "                filters in the layer.\n",
    "            nlen: Number of columns in the input of that layer. \n",
    "        \n",
    "        Returns:\n",
    "            An (nlen - k + 1) * nf x nlen * N matrix that can be used to\n",
    "            perform the convolution when multiplied by the\n",
    "            vectorized input.\n",
    "        \"\"\"\n",
    "        nf = F.shape[2]\n",
    "        vec_filters = F.transpose(2,1,0).reshape(nf, F.shape[0] * F.shape[1])\n",
    "        MF_matrix = np.zeros(((nlen - F.shape[1] + 1) * nf, nlen * F.shape[0]))\n",
    "        cur_column = 0\n",
    "        # For each time the filters are applied\n",
    "        for i in range(nlen - F.shape[1] + 1):\n",
    "            # Fill in the zero slots of the MF_Matrix with the vectorized filters\n",
    "            MF_matrix[i * nf: i * nf + nf, cur_column *  F.shape[0]: cur_column *  F.shape[0] + vec_filters.shape[1]] = vec_filters\n",
    "            cur_column += 1\n",
    "        return MF_matrix\n",
    "        \n",
    "    def makeMXMatrix(self, vec_input, height, width, nf, nlen):\n",
    "        \"\"\"\n",
    "        Computes the input matrix used for the convolutions during the \n",
    "        back-propagation.\n",
    "        \n",
    "        Args:\n",
    "            vec_input: Vectorized version of the input to the convolutional\n",
    "                layer.\n",
    "            height: corresponding height of the filter\n",
    "            width: corresponding width of the filter\n",
    "            filter_no: number of filters to be applied\n",
    "            nlen: Number of columns in the input of that layer. \n",
    "        Returns:\n",
    "            A (nlen - k + 1) * filter_no x k * filter_no * height with the\n",
    "            results of the convolutions.\n",
    "        \"\"\"\n",
    "        MX_Matrix = np.zeros(((nlen - width + 1) * nf, width * nf * height))\n",
    "        cur_column = 0\n",
    "        for i in range(nlen - width + 1):\n",
    "            # Define block diagonal matrix with the inputs to be used in this convolution on the diagonal\n",
    "            MX_Matrix[i * nf : i * nf + nf, :] = \\\n",
    "                block_diag(*[vec_input[cur_column * height: cur_column * height + width * height] for j in range(nf)]) \n",
    "            cur_column += 1\n",
    "        return MX_Matrix\n",
    "    \n",
    "    def cross_entropy_loss(self, X, Y, MFs):\n",
    "        \"\"\"\n",
    "        Calculates the cross entropy loss\n",
    "        \"\"\"\n",
    "        log_X = np.multiply(Y , self.forwardPass(X, MFs)[0]).sum(axis=0)\n",
    "        log_X[log_X == 0] = np.finfo(float).eps\n",
    "        return -np.log(log_X)\n",
    "\n",
    "    \n",
    "    def computeLoss(self, X_batch, Y_batch, MFs):\n",
    "        \"\"\"\n",
    "        Computes the loss of the network given a batch of data.\n",
    "        \n",
    "        Args:\n",
    "            X_batch: NxD matrix with N data sample inputs\n",
    "            Y_batch: NxM matrix with N data sample outputs\n",
    "        \n",
    "        Returns:\n",
    "            A scalar float value corresponding to the loss.\n",
    "        \"\"\"        \n",
    "        return np.mean(self.cross_entropy_loss(X_batch, Y_batch, MFs))# + lamda * np.sum(self.W ** 2)\n",
    "\n",
    "    def computeAccuracy(self, X, y, MFs):\n",
    "        \"\"\"\n",
    "        Computes the accuracy of the network.\n",
    "\n",
    "        Args:\n",
    "            X: Input matrix\n",
    "            y: Output labels\n",
    "\n",
    "        Returns:\n",
    "            The accuracy of the network (i.e. the percentage of\n",
    "            correctly classified inputs in X).\n",
    "\n",
    "        \"\"\"\n",
    "        softmax_outputs = self.forwardPass(X, MFs)[0] # Get probability distribution of outputs\n",
    "        # Reduce to a vector of the labels with the highest probability\n",
    "        predictions = np.argmax(softmax_outputs, axis = 0)\n",
    "        accuracy = (predictions == y).mean()\n",
    "        return accuracy\n",
    "\n",
    "    def forwardPass(self, X_batch, MFs):\n",
    "        \"\"\"\n",
    "        Performs a forward pass and returns the result:\n",
    "        \n",
    "        Args:\n",
    "            X_batch: NxD matrix with N data sample inputs\n",
    "            MFs: Matrices needed to perform convolution as \n",
    "                matrix multiplication.\n",
    "            \n",
    "        Returns:\n",
    "            A matrix with the predicted one-hot representations along with the outputs\n",
    "            of the first and second layer as well as the MF matrices calculated.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply first convolutional layer to input data followed by a ReLU activation\n",
    "        X_batch1 = MFs[0].dot(X_batch)\n",
    "        X_batch1[X_batch1 < 0.0] = 0.0\n",
    "        \n",
    "        # Apply second convolutional layer to input data followed by a ReLU activation\n",
    "        X_batch2 = MFs[1].dot(X_batch1)\n",
    "        X_batch2[X_batch2 < 0.0] = 0.0\n",
    "        \n",
    "        # Apply the fully connected layer\n",
    "        output = self.W.dot(X_batch2)\n",
    "        # Apply softmax\n",
    "        P_batch = self.softmax(output)\n",
    "        return P_batch, X_batch1, X_batch2\n",
    "    \n",
    "    def backwardPass(self, Y_batch, P_batch, X_batch, X_batch1, X_batch2, MFs):\n",
    "        \"\"\"\n",
    "        Performs a backward pass and returns the gradients:\n",
    "        \n",
    "        Args:\n",
    "            Y_batch: NxM matrix with N data sample outputs\n",
    "            P_batch: Output after the softmax activation layer\n",
    "            X_batch2: Output of the second convolutional layer after the ReLU.\n",
    "            X_batch1: Output of the first convolutional layer after the ReLU.\n",
    "            X_batch: Original batch with the inputs.\n",
    "            MFs: Matrices needed to perform convolution as \n",
    "                matrix multiplication.\n",
    "            \n",
    "        Returns:\n",
    "            The gradients of the weights of each layer (i.e. grad_F1, grad_F2, grad_W).\n",
    "        \"\"\"\n",
    "        # Initialize all gradients to zero\n",
    "        grad_W = np.zeros(self.W.shape) \n",
    "        grad_F1 = np.zeros(self.F[0].shape)\n",
    "        grad_F2 = np.zeros(self.F[1].shape)\n",
    "        \n",
    "        # Compute gradient of W\n",
    "        n = Y_batch.shape[1]\n",
    "        G_batch = -(Y_batch - P_batch)\n",
    "        grad_W = G_batch.dot(X_batch2.T) / n\n",
    "        \n",
    "        \n",
    "        # Propagate gradient through fully connected layer and ReLU of 2nd layer\n",
    "        G_batch = self.W.T.dot(G_batch)\n",
    "        G_batch *= np.where(X_batch2 > 0, 1, 0)\n",
    "        \n",
    "        # Compute gradient of the second layer's filters\n",
    "        n = X_batch1.shape[1]\n",
    "        for j in range(n):\n",
    "            g_j = G_batch[:,j]\n",
    "            x_j = X_batch1[:,j]\n",
    "            MX_matrix = self.makeMXMatrix(x_j, *self.F[1].shape, self.nlen_list[0])\n",
    "            v = g_j.T.dot(MX_matrix)\n",
    "            grad_F2 += v.reshape(grad_F2.shape, order='F')\n",
    "        grad_F2 /= n\n",
    "        \n",
    "        # Propagate gradient through second convolutional layer and ReLU of 1st layer\n",
    "        G_batch = MFs[1].T.dot(G_batch)\n",
    "        G_batch *= np.where(X_batch1 > 0, 1, 0)\n",
    "        \n",
    "        # Compute gradient of the first layer's filters\n",
    "        n = X_batch.shape[1]\n",
    "        for j in range(n):\n",
    "            g_j = G_batch[:,j]\n",
    "            x_j = X_batch[:,j]\n",
    "            MX_matrix = self.makeMXMatrix(x_j, *self.F[0].shape, self.max_length)\n",
    "            v = g_j.T.dot(MX_matrix)\n",
    "            grad_F1 += v.reshape(grad_F1.shape, order='F')\n",
    "        grad_F1 /= n       \n",
    "        \n",
    "        return grad_F1, grad_F2, grad_W\n",
    "    \n",
    "\n",
    "\n",
    "    def compute_grad_num_slow(self, X_batch, Y_batch, h = 1e-6):\n",
    "        '''Centered difference gradient'''\n",
    "        # Initialize all gradients to zero\n",
    "        grad_W = np.zeros(self.W.shape) \n",
    "        grad_F1 = np.zeros(self.F[0].shape)\n",
    "        grad_F2 = np.zeros(self.F[1].shape)\n",
    "\n",
    "        MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "        MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0]))\n",
    "        \n",
    "        for j in tqdm(range(self.W.shape[0])):\n",
    "            for k in range(self.W.shape[1]):\n",
    "                self.W[j, k] -= h\n",
    "                c1 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "                self.W[j, k] += 2 * h\n",
    "                c2 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "                self.W[j, k] -= h\n",
    "                grad_W[j, k] = (c2-c1) / (2 * h)\n",
    "        \n",
    "        \n",
    "        for j in tqdm(range(self.F[1].shape[0])):\n",
    "            for k in range(self.F[1].shape[1]):\n",
    "                for i in range(self.F[1].shape[2]):\n",
    "                    self.F[1][j, k, i] -= h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c1 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[1][j, k, i]  += 2 * h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c2= self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[1][j, k, i]  -= h\n",
    "                    grad_F2[j, k, i]  = (c2-c1) / (2 * h)\n",
    "\n",
    "        \n",
    "        for j in tqdm(range(self.F[0].shape[0])):\n",
    "            for k in range(self.F[0].shape[1]):\n",
    "                for i in range(self.F[0].shape[2]):\n",
    "                    self.F[0][j, k, i]  -= h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c1 = self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[0][j, k, i]  += 2 * h\n",
    "                    MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                    MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0])) \n",
    "                    c2= self.computeLoss(X_batch, Y_batch, MFs);\n",
    "\n",
    "                    self.F[0][j, k, i]  -= h\n",
    "                    grad_F1[j, k, i] = (c2-c1) / (2 * h)\n",
    "\n",
    "                \n",
    "        return grad_F1, grad_F2, grad_W\n",
    "    \n",
    "    def miniBatchGD(self, X, Y, GDparams, verbose = False, X_val = None, Y_val = None, tol = 1e-10):\n",
    "        \"\"\"\n",
    "        Implementation of mini-batch gradient descent.\n",
    "\n",
    "         Args:\n",
    "            X: Training input matrix\n",
    "            Y: Training set desired output matrix\n",
    "            GDparams: Object of the class Params with the hyperparameters\n",
    "                used for learning.\n",
    "            verbose: Prints info in each iteration about the progress of\n",
    "                training when equal to True.\n",
    "            X_val: Validation set input matrix\n",
    "            Y_val: Validation set desired output matrix\n",
    "\n",
    "        Returns:\n",
    "            The following tuple is returned where the validation lists\n",
    "            are empty if no validation set is given: (training_loss_list,\n",
    "            validation_loss_list, training_acc_list, validation_acc_list).\n",
    "        \"\"\"\n",
    "        results = ([],[],[],[])\n",
    "        mini_batch_count = X.shape[0] // GDparams.n_batch\n",
    "        y = np.argmax(Y, axis = 0)\n",
    "        \n",
    "        MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "        MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0]))\n",
    "        \n",
    "        if(X_val is not None and Y_val is not None):\n",
    "            y_val = np.argmax(Y_val, axis = 0)\n",
    "        results[0].append(self.computeLoss(X, Y, MFs))\n",
    "        results[2].append(self.computeAccuracy(X, y, MFs))\n",
    "        \n",
    "        if(X_val is not None and Y_val is not None):\n",
    "            results[1].append(self.computeLoss(X_val, Y_val, MFs))\n",
    "            results[3].append(self.computeAccuracy(X_val, y_val, MFs))\n",
    "            \n",
    "        if(verbose):\n",
    "                print(\"Starting state \")\n",
    "                print(\"    Training cost: \" + str(results[0][-1]))\n",
    "                print(\"    Training accuracy: \" + str(results[2][-1]))\n",
    "                if(X_val is not None and Y_val is not None):\n",
    "                    print(\"    Validation cost: \" + str(results[1][-1]))\n",
    "                    print(\"    Validation accuracy: \" + str(results[3][-1]))\n",
    "                    \n",
    "        # If momentum is used\n",
    "        if GDparams.rho != 0.0:\n",
    "            # Create zero matrix for each parameter\n",
    "            V_W = np.zeros(self.W.shape)\n",
    "            V_F2 = np.zeros(self.F[1].shape)\n",
    "            V_F1 = np.zeros(self.F[0].shape)\n",
    "                    \n",
    "        learning_rate = GDparams.eta\n",
    "        for i in tqdm(range(GDparams.n_epochs)):\n",
    "            for j in range(mini_batch_count):\n",
    "                if(j < mini_batch_count - 1):\n",
    "                    start = j * GDparams.n_batch\n",
    "                    end = start + GDparams.n_batch\n",
    "                    mini_batch_input = X[:,start:end]\n",
    "                    mini_batch_output = Y[:,start:end]\n",
    "                else:\n",
    "                    # Take the remaining samples in the last mini batch\n",
    "                    mini_batch_input = X[:,j * GDparams.n_batch:]\n",
    "                    mini_batch_output = Y[:,j * GDparams.n_batch:]\n",
    "                \n",
    "                # Construct MF Matrices\n",
    "                MFs = [self.constructFilterMatrix(self.F[0], self.max_length)]\n",
    "                MFs.append(self.constructFilterMatrix(self.F[1], self.nlen_list[0]))\n",
    "                P_batch, X_batch1, X_batch2 = self.forwardPass(mini_batch_input, MFs)\n",
    "                grad_F1, grad_F2, grad_W = self.backwardPass(mini_batch_output, P_batch, mini_batch_input,\\\n",
    "                                                             X_batch1, X_batch2, MFs)\n",
    "\n",
    "                # Converge if all gradients are zero\n",
    "                if np.all(grad_W < tol) == 0 and np.all(grad_F1 < tol) and np.all(grad_F2 < tol):\n",
    "                    print(\"Learning converged at epoch \" + str(i))\n",
    "                    break              \n",
    "                \n",
    "                if GDparams.rho == 0.0:\n",
    "                    self.W[0] -= learning_rate * grad_W\n",
    "                    self.F[1] -= learning_rate * grad_F2\n",
    "                    self.F[0] -= learning_rate * grad_F1\n",
    "                else:\n",
    "                    V_W = GDparams.rho * V_W + learning_rate * grad_W\n",
    "                    V_F2 = GDparams.rho * V_F2 + learning_rate * grad_F2\n",
    "                    V_F1 = GDparams.rho * V_F1 + learning_rate * grad_F1\n",
    "                    self.W -= V_W\n",
    "                    self.F[1] -= V_F2\n",
    "                    self.F[0] -= V_F1\n",
    "                    \n",
    "            # Decay the learning rate\n",
    "            learning_rate *= GDparams.decay_rate\n",
    "\n",
    "            results[0].append(self.computeLoss(X, Y, MFs))\n",
    "            results[2].append(self.computeAccuracy(X, y, MFs))\n",
    "            if(X_val is not None and Y_val is not None):\n",
    "                results[1].append(self.computeLoss(X_val, Y_val, MFs))\n",
    "                results[3].append(network_model.computeAccuracy(X_val, y_val, MFs))\n",
    "            if(verbose):\n",
    "                print(\"Iteration \" + str(i))\n",
    "                print(\"    Training cost: \" + str(results[0][-1]))\n",
    "                print(\"    Training accuracy: \" + str(results[2][-1]))\n",
    "                if(X_val is not None and Y_val is not None):\n",
    "                    print(\"    Validation cost: \" + str(results[1][-1]))\n",
    "                    print(\"    Validation accuracy: \" + str(results[3][-1]))\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    \"\"\"\n",
    "    Class containing hyperparameters used for\n",
    "    gradient descent learning.\n",
    "    \n",
    "    Attributes:\n",
    "        n_batch: Number of samples in each mini-batch.\n",
    "        eta: Learning rate\n",
    "        n_epochs: Maximum number of learning epochs.\n",
    "        decay_rate: The percentage of decay of the learning rate after each epoch, i.e.\n",
    "            a factor less than 1 by which the learning rate gets multiplied after each \n",
    "            epoch.\n",
    "        rho: percentage of use of the gradients of previous turns in learning to add momentum\n",
    "    \"\"\"\n",
    "    def __init__(self, n_batch, eta, n_epochs, decay_rate = 1.0, rho = 0.0):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.n_batch = n_batch\n",
    "        self.eta = eta\n",
    "        self.n_epochs = n_epochs\n",
    "        self.decay_rate = decay_rate\n",
    "        self.rho = rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelativeErrors(grad1, grad2):\n",
    "    \"\"\"\n",
    "    Computes the relative errors of grad_1 and grad_2 gradients\n",
    "    \"\"\"\n",
    "    abs_diff = np.absolute(grad1 - grad2) \n",
    "    abs_sum = np.absolute(grad1) + np.absolute(grad2)\n",
    "    max_elems = np.where(abs_sum > np.finfo(float).eps, abs_sum, np.finfo(float).eps)\n",
    "    relativeErrors = abs_diff / max_elems\n",
    "    return relativeErrors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeString(string, character_dictionary, max_length):\n",
    "    \"\"\"\n",
    "    One-hot encodes the character string, converting each \n",
    "    of its letters to one-hot encoded vectors and stacking\n",
    "    them from left to right. \n",
    "    \n",
    "    Args:\n",
    "        name: The string to be encoded.\n",
    "        character_dictionary: A dictionary which has a unique\n",
    "            index for each character in the alphabet used by\n",
    "            the string.\n",
    "        max_length: maximum length of the string. If the string\n",
    "            has a length less than max_length, zero columnds are\n",
    "            added as padding after the encoded character columns.\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "        A C x max_length vector with the one-hot encoded characters\n",
    "        of the string and possibly zero padding in the last columns\n",
    "        where C is the number of different characters in the alpha-\n",
    "        bet used.\n",
    "    \"\"\"\n",
    "    d = len(character_dictionary)\n",
    "    encoded_string = np.zeros((d, max_length))\n",
    "    for i in range(len(string)):\n",
    "        encoded_string[character_dictionary[string[i]],i] = 1\n",
    "    return encoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(label_id, label_no):\n",
    "    \"\"\"\n",
    "    Returns a one-hot encoded numpy vector with 1 at the index\n",
    "    of the label and 0 for each other element.\n",
    "    \n",
    "    Args:\n",
    "        label_id: Index of label.\n",
    "        label_no: Number of total labels.\n",
    "    \n",
    "    Returns:\n",
    "        A one-hot encoded vector with label_no elements.\n",
    "    \"\"\"\n",
    "    vector = np.zeros(label_no) \n",
    "    vector[label_id] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the files containing the data\n",
    "name_path = \"ascii_names.txt\"\n",
    "category_labels_path = \"category_labels.txt\"\n",
    "# Path to file used to save the inputs after their encoding\n",
    "save_input_path = \"onehot_encoded_inputs.npy\"\n",
    "# Path to file with the indices of the inputs that are going to used in the validation set\n",
    "val_ind_path = \"Validation_Inds.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20050it [00:00, 954863.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "names = []\n",
    "labels = []\n",
    "if(os.path.exists(name_path)):\n",
    "    with open(name_path,\"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            entry = line.split()\n",
    "            names.append(' '.join(entry[:-1]))\n",
    "            labels.append(entry[-1])\n",
    "    f.close()\n",
    "    names = np.array(names)\n",
    "    labels = np.array(labels, dtype = int) \n",
    "else:\n",
    "    print(\"Requested file \" + name_path + \" does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Arabic\n"
     ]
    }
   ],
   "source": [
    "# Read the different class names and indices and build a dictionary\n",
    "if(os.path.exists(category_labels_path)):\n",
    "    class_names = np.loadtxt(category_labels_path, usecols = 1, dtype = str)\n",
    "    class_indices = np.loadtxt(category_labels_path, usecols = 0, dtype = int)\n",
    "    K = len(class_names)\n",
    "    class_dictionary = {}\n",
    "    for i in range(K):\n",
    "        class_dictionary[class_names[i]] = class_indices[i]\n",
    "    inv_class_dictionary = {v: k for k, v in class_dictionary.items()}\n",
    "    # Check for correctness\n",
    "    print(class_dictionary['Arabic'])\n",
    "    print(inv_class_dictionary[1])\n",
    "else: \n",
    "    print(\"Requested file \" + category_labels_path + \" does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine number of unique characters and set up dictionary / Determine maximum length of name in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 20050/20050 [00:00<00:00, 445465.11it/s]\n"
     ]
    }
   ],
   "source": [
    "character_dictionary = {}\n",
    "unique_idx = 0\n",
    "max_length = -1\n",
    "for name in tqdm(names):\n",
    "    length = len(name)\n",
    "    if(length > max_length):\n",
    "        max_length = length\n",
    "    for i in range(len(name)):\n",
    "        if(name[i] not in character_dictionary.keys()):\n",
    "            character_dictionary[name[i]] = unique_idx\n",
    "            unique_idx += 1\n",
    "d = len(character_dictionary) # Get number of unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFFERENT UNIQUE CHARACTERS: 55\n",
      "MAXIMUM NAME LENGTH: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"DIFFERENT UNIQUE CHARACTERS: \" + str(d))\n",
    "print(\"MAXIMUM NAME LENGTH: \" + str(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# Build inverse dictionary mapping\n",
    "inv_character_dictionary = {v: k for k, v in character_dictionary.items()}\n",
    "# Check for correctness\n",
    "print(character_dictionary['o'])\n",
    "print(inv_character_dictionary[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding and vectorization of the input names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 20050/20050 [00:00<00:00, 31623.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode and save the inputs in a matrix when each column corresponds to a different name\n",
    "vectorized_input_size = d * max_length\n",
    "X = np.zeros((vectorized_input_size, names.shape[0]))\n",
    "for idx, name in enumerate(tqdm(names)):\n",
    "    X[:,idx] = encodeString(name, character_dictionary, max_length).flatten(order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save inputs in a file if they are not already saved\n",
    "if(not os.path.exists(save_input_path)):\n",
    "    np.save(save_input_path, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the inputs that are going to used in the validation set\n",
    "if(os.path.exists(val_ind_path)):\n",
    "    validation_indices = np.loadtxt(val_ind_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for outputputs\n",
    "Y = np.array([one_hot_encoding(label - 1, K) for label in labels], order = 'F').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters & initialize the ConvNet's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_width_constants = [3, 3]\n",
    "K = len(class_dictionary)\n",
    "conv_net = ConvNet(n = filter_numbers , k = filter_width_constants, output_dim = K, \\\n",
    "                   input_dim = d, nlen = max_length, he_init = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Debug based on saved filters and convolution outputs\n",
    "dictionary = loadmat(\"Debugging_files/DebugInfo\")\n",
    "x_input = dictionary['x_input'].reshape(1, -1)\n",
    "X_input = dictionary['X_input']\n",
    "F = dictionary['F']\n",
    "vecS = dictionary['vecS']\n",
    "MF_Matrix = conv_net.constructFilterMatrix(F, max_length)\n",
    "s = MF_Matrix.dot(x_input.reshape(-1, 1)).flatten()\n",
    "print(np.allclose(s, vecS.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_Matrix = conv_net.constructFilterMatrix(conv_net.F[0], max_length)\n",
    "MF_Matrix2 = conv_net.constructFilterMatrix(conv_net.F[1], conv_net.nlen_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f780136ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f780139588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the mf_matrix to confirm that it is block diagonal\n",
    "plt.pcolormesh(MF_Matrix)\n",
    "plt.show()\n",
    "plt.pcolormesh(MF_Matrix2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "MX_Matrix = conv_net.makeMXMatrix((X[:,17513]), *conv_net.F[0].shape, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Debugging for make MX and make MF functions (s1 and s2 should be equal)\n",
    "s1 = MX_Matrix.dot(conv_net.F[0].flatten('F').reshape(-1, 1))\n",
    "s2 = MF_Matrix.dot(X[:,17513].reshape(-1, 1))\n",
    "print(np.allclose(s1,s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct MF Matrices\n",
    "MFs = [conv_net.constructFilterMatrix(conv_net.F[0], conv_net.max_length)]\n",
    "MFs.append(conv_net.constructFilterMatrix(conv_net.F[1], conv_net.nlen_list[0]))\n",
    "P_batch, X_batch1, X_batch2 = conv_net.forwardPass(X[:,:100], MFs)\n",
    "grad_F1, grad_F2, grad_W = conv_net.backwardPass(Y[:,:100], P_batch, X[:,:100], X_batch1, X_batch2, MFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:01<00:00,  9.41it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 42.19it/s]\n",
      "100%|██████████████████████████████████████████| 55/55 [00:01<00:00, 43.29it/s]\n"
     ]
    }
   ],
   "source": [
    "grad_F1_approx, grad_F2_approx, grad_W_approx = conv_net.compute_grad_num_slow(X[:,:100], Y[:,:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5621700030024485e-06\n",
      "5.145863951394146e-07\n",
      "7.230137495339259e-05\n",
      "2.017977928912094e-08\n",
      "1.4395526929767264e-08\n",
      "2.0569427892524923e-07\n"
     ]
    }
   ],
   "source": [
    "errors1 = getRelativeErrors(grad_F1, grad_F1_approx)\n",
    "errors2 = getRelativeErrors(grad_F2, grad_F2_approx)\n",
    "errors3 = getRelativeErrors(grad_W, grad_W_approx)\n",
    "print(np.max(errors1))\n",
    "print(np.max(errors2))\n",
    "print(np.max(errors3))\n",
    "\n",
    "print(np.mean(errors1))\n",
    "print(np.mean(errors2))\n",
    "print(np.mean(errors3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state \n",
      "    Training cost: 2.90296377701524\n",
      "    Training accuracy: 0.06892768079800499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/5 [00:00<?, ?it/s]D:\\Anaconda3\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "    Training cost: 7.480981186177933\n",
      "    Training accuracy: 0.09975062344139651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 1/5 [00:34<02:19, 34.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "    Training cost: 5.044968199753777\n",
      "    Training accuracy: 0.10658354114713217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 2/5 [01:10<01:45, 35.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2\n",
      "    Training cost: 2.856799804314617\n",
      "    Training accuracy: 0.21531172069825436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 3/5 [01:45<01:10, 35.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3\n",
      "    Training cost: 3.929894385940249\n",
      "    Training accuracy: 0.1543640897755611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 4/5 [02:20<00:35, 35.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4\n",
      "    Training cost: 3.0016638358951915\n",
      "    Training accuracy: 0.21381546134663343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [02:54<00:00, 35.00s/it]\n"
     ]
    }
   ],
   "source": [
    "rho = 0.9\n",
    "epochs = 5\n",
    "mini_batch_size = 100\n",
    "decay_rate = 0.95\n",
    "eta = 0.05\n",
    "GDparams = Params(mini_batch_size, eta, epochs, decay_rate, rho)\n",
    "results = conv_net.miniBatchGD(X, Y, GDparams, verbose = True, X_val = None, Y_val = None, tol = 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
